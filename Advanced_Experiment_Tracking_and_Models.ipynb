{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33eda753-6a47-49b8-ac40-e2f0e44f00a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Dual Model System - Complete Implementation Guide\n",
    "\n",
    "**Overview:**\n",
    "\n",
    "Flightmasters system now uses TWO separate models:\n",
    "\n",
    "-Pre-Departure Model :- Predicts delays BEFORE flight takes off\n",
    "\n",
    "-In-Flight Model :- Predicts delays AFTER takeoff (more accurate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ad9ec54-3d54-4ae8-abd7-f6eeb9f61682",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Why create 2 models?\n",
    "\n",
    "dep_delay is one of the STRONGEST predictors of arr_delay\n",
    "\n",
    "If a flight departs 20 minutes late, it's likely to arrive late too\n",
    "\n",
    "Pre-departure model must rely on other signals (time of day, route, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de21fdec-40a6-4cbc-9c1a-49719cc88b47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Description and details:\n",
    "\n",
    "Trains 4 models:\n",
    "\n",
    "1. Random Forest (Pre-Departure)\n",
    "2. GBT (Pre-Departure)\n",
    "3. Random Forest (In-Flight)\n",
    "4. GBT (In-Flight)\n",
    "\n",
    "Features:\n",
    "\n",
    "1. Bayesian optimization (smart parameter tuning)\n",
    "2. 5-fold cross-validation (reliable metrics)\n",
    "3. MLflow tracking (experiment management)\n",
    "\n",
    "Runtime: ~15 hours total\n",
    "\n",
    "Pre-Departure models: ~6 hours\n",
    "In-Flight models: ~9 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4de3be55-59ed-408c-ab5d-502b69c697e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Steps to run:\n",
    "Run all the cells in the notebook after you change your email at the bottom of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a187f13-5f39-4540-8d76-7e02458a4e94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b5af1df1-361f-444e-b2fa-00de923644db/lib/python3.12/site-packages (0.2.7)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.12/site-packages (from hyperopt) (2.1.3)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.12/site-packages (from hyperopt) (1.15.1)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from hyperopt) (1.16.0)\nRequirement already satisfied: networkx>=2.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b5af1df1-361f-444e-b2fa-00de923644db/lib/python3.12/site-packages (from hyperopt) (3.6)\nRequirement already satisfied: future in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b5af1df1-361f-444e-b2fa-00de923644db/lib/python3.12/site-packages (from hyperopt) (1.0.0)\nRequirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b5af1df1-361f-444e-b2fa-00de923644db/lib/python3.12/site-packages (from hyperopt) (4.67.1)\nRequirement already satisfied: cloudpickle in /databricks/python3/lib/python3.12/site-packages (from hyperopt) (3.0.0)\nRequirement already satisfied: py4j in /databricks/python3/lib/python3.12/site-packages (from hyperopt) (0.10.9.9)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35843a79-4a4d-44ba-9db9-3d9edd4f002c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python3\n",
    "# \"\"\"\n",
    "# Optimized ML Experiments for Databricks Community Edition\n",
    "# - FIXED: Logs models to workspace registry with signatures\n",
    "# - Models can be registered to UC manually via UI/API after logging\n",
    "# - Avoids MLeap dependency issue on Community Edition\n",
    "# \"\"\"\n",
    "\n",
    "# import warnings\n",
    "# import os\n",
    "# import mlflow\n",
    "# import mlflow.spark\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "# from pyspark.ml.classification import GBTClassifier, RandomForestClassifier\n",
    "# from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "# from pyspark.ml.tuning import CrossValidator\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import col, udf\n",
    "# from pyspark.sql.types import DoubleType\n",
    "# from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "# # Signature imports\n",
    "# from mlflow.models.signature import ModelSignature\n",
    "# from mlflow.types.schema import Schema, TensorSpec\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # CONFIGURATION\n",
    "# # =============================================================================\n",
    "\n",
    "# class Config:\n",
    "#     \"\"\"Optimized for Databricks Community Edition\"\"\"\n",
    "    \n",
    "#     TOP_K_FEATURES = 40 \n",
    "#     CV_FOLDS = 2\n",
    "#     BAYES_MAX_EVALS = 4\n",
    "#     TEST_RATIO = 0.2\n",
    "#     RANDOM_SEED = 42\n",
    "    \n",
    "#     GOLD_TABLE = \"default.gold_ml_features_experimental\"\n",
    "#     EXPERIMENT_NAME = \"/Shared/Flightmasters_Optimized_Experiments\"\n",
    "    \n",
    "#     # CRITICAL CHANGE: Use workspace registry for initial logging\n",
    "#     MLFLOW_TRACKING_URI = \"databricks\"\n",
    "#     MLFLOW_REGISTRY_URI = \"databricks\"  \n",
    "    \n",
    "#     # Model names (without UC prefix for workspace registry)\n",
    "#     MODEL_RF_PRE = \"model_rf_pre\"\n",
    "#     MODEL_GBT_PRE = \"model_gbt_pre\"\n",
    "#     MODEL_RF_IN = \"model_rf_in\"\n",
    "#     MODEL_GBT_IN = \"model_gbt_in\"\n",
    "    \n",
    "#     # UC settings (for manual registration later)\n",
    "#     UC_CATALOG = \"workspace\"\n",
    "#     UC_SCHEMA = \"default\"\n",
    "#     UC_VOLUME_NAME = \"mlflow_shared_tmp\"\n",
    "    \n",
    "#     USE_CHECKPOINTING = True\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # HELPERS\n",
    "# # =============================================================================\n",
    "\n",
    "# def setup_uc_volume(spark):\n",
    "#     \"\"\"Setup Unity Catalog Volume for artifacts\"\"\"\n",
    "#     catalog = Config.UC_CATALOG\n",
    "#     schema = Config.UC_SCHEMA\n",
    "#     volume_name = Config.UC_VOLUME_NAME\n",
    "    \n",
    "#     volume_path = f\"{catalog}.{schema}.{volume_name}\"\n",
    "#     env_path = f\"/Volumes/{catalog}/{schema}/{volume_name}\"\n",
    "    \n",
    "#     print(\"\\n\" + \"=\" * 80)\n",
    "#     print(f\"UNITY CATALOG VOLUME SETUP\")\n",
    "#     print(\"=\" * 80)\n",
    "#     print(f\"Volume Target: {volume_path}\")\n",
    "    \n",
    "#     try:\n",
    "#         volume_exists = spark.sql(f\"SHOW VOLUMES IN {catalog}.{schema}\").filter(\n",
    "#             col(\"volume_name\") == volume_name\n",
    "#         ).count() > 0\n",
    "        \n",
    "#         if not volume_exists:\n",
    "#             spark.sql(f\"CREATE VOLUME {volume_path}\")\n",
    "#             print(\"‚úÖ Volume created successfully.\")\n",
    "#         else:\n",
    "#             print(\"‚úÖ Volume already exists.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ö†Ô∏è  WARNING: Could not check/create volume: {e}\")\n",
    "#         pass\n",
    "        \n",
    "#     os.environ['MLFLOW_DFS_TMP'] = env_path\n",
    "#     os.environ['SPARKML_TEMP_DFS_PATH'] = env_path\n",
    "    \n",
    "#     print(f\"‚úÖ Environment paths set to: {env_path}\")\n",
    "#     return volume_path\n",
    "\n",
    "\n",
    "# def create_safe_vector_slicer(indices_to_keep):\n",
    "#     \"\"\"Create UDF to slice vectors\"\"\"\n",
    "#     indices_list = list(indices_to_keep)\n",
    "    \n",
    "#     @udf(returnType=VectorUDT())\n",
    "#     def safe_slicer(features):\n",
    "#         if features is None: \n",
    "#             return None\n",
    "#         max_idx = features.size - 1\n",
    "#         selected_values = [float(features[i]) for i in indices_list if i <= max_idx]\n",
    "#         return Vectors.dense(selected_values)\n",
    "    \n",
    "#     return safe_slicer\n",
    "\n",
    "\n",
    "# def checkpoint_if_enabled(df, eager=True):\n",
    "#     \"\"\"Checkpoint data to prevent OOM\"\"\"\n",
    "#     if Config.USE_CHECKPOINTING:\n",
    "#         return df.localCheckpoint(eager=eager)\n",
    "#     return df\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # 1. FEATURE IMPORTANCE\n",
    "# # =============================================================================\n",
    "\n",
    "# def analyze_feature_importance(train_data, top_k):\n",
    "#     print(\"\\n\" + \"=\" * 80)\n",
    "#     print(\"PHASE 1: FEATURE IMPORTANCE ANALYSIS\")\n",
    "#     print(\"=\" * 80)\n",
    "    \n",
    "#     sample = train_data.select(\"features\").first()\n",
    "#     if not sample:\n",
    "#         raise ValueError(\"Training data is empty or features column is missing.\")\n",
    "        \n",
    "#     total_features = sample.features.size\n",
    "#     print(f\"\\nüìä Original features: {total_features}\")\n",
    "    \n",
    "#     print(\"\\nüå≤ Training Random Forest for feature ranking...\")\n",
    "#     rf = RandomForestClassifier(\n",
    "#         featuresCol=\"features\", labelCol=\"label\",\n",
    "#         numTrees=30, maxDepth=8, seed=Config.RANDOM_SEED\n",
    "#     )\n",
    "    \n",
    "#     rf_model = rf.fit(train_data)\n",
    "#     importances = rf_model.featureImportances.toArray()\n",
    "    \n",
    "#     top_k_indices = np.argsort(importances)[-top_k:][::-1]\n",
    "#     top_k_scores = importances[top_k_indices]\n",
    "    \n",
    "#     selected_importance = np.sum(top_k_scores)\n",
    "#     total_importance = np.sum(importances)\n",
    "#     retention = (selected_importance / total_importance) * 100\n",
    "    \n",
    "#     print(f\"\\nüìà Feature Selection Summary:\")\n",
    "#     print(f\"   Original: {total_features} -> Selected: {top_k}\")\n",
    "#     print(f\"   Information retained: {retention:.1f}%\")\n",
    "    \n",
    "#     return total_features, top_k_indices.tolist(), retention\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # 2. CREATE DUAL DATASETS\n",
    "# # =============================================================================\n",
    "\n",
    "# def create_dual_datasets(df_gold, selected_indices, dep_delay_orig_index=11):\n",
    "#     print(\"\\n\" + \"=\" * 80)\n",
    "#     print(\"PHASE 2: CREATING DUAL DATASETS\")\n",
    "#     print(\"=\" * 80)\n",
    "    \n",
    "#     dep_delay_in_selected = dep_delay_orig_index in selected_indices\n",
    "#     if dep_delay_in_selected: \n",
    "#         print(f\"‚úÖ dep_delay found at original index {dep_delay_orig_index}\")\n",
    "#     else: \n",
    "#         print(f\"‚ö†Ô∏è  dep_delay (index {dep_delay_orig_index}) not in top-K\")\n",
    "    \n",
    "#     print(f\"\\nüîß Applying feature selection...\")\n",
    "#     slicer_udf = create_safe_vector_slicer(selected_indices)\n",
    "#     df_selected = df_gold.withColumn(\"features\", slicer_udf(col(\"features\"))).select(\"features\", \"label\")\n",
    "#     df_selected = df_selected.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
    "#     df_selected = checkpoint_if_enabled(df_selected)\n",
    "    \n",
    "#     if dep_delay_in_selected:\n",
    "#         print(f\"\\nüìã Creating Pre-Departure (removing dep_delay)...\")\n",
    "#         dep_delay_new_index = selected_indices.index(dep_delay_orig_index)\n",
    "#         pre_dep_indices = [i for i in range(len(selected_indices)) if i != dep_delay_new_index]\n",
    "#         pre_dep_slicer = create_safe_vector_slicer(pre_dep_indices)\n",
    "#         df_pre_dep = df_selected.withColumn(\"features\", pre_dep_slicer(col(\"features\"))).select(\"features\", \"label\")\n",
    "#     else:\n",
    "#         df_pre_dep = df_selected\n",
    "    \n",
    "#     df_in_flight = df_selected\n",
    "    \n",
    "#     df_pre_dep = checkpoint_if_enabled(df_pre_dep, eager=False)\n",
    "#     df_in_flight = checkpoint_if_enabled(df_in_flight, eager=False)\n",
    "    \n",
    "#     return df_pre_dep, df_in_flight, dep_delay_in_selected\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # 3. TRAIN/TEST SPLIT\n",
    "# # =============================================================================\n",
    "\n",
    "# def split_and_checkpoint(df, name):\n",
    "#     print(f\"\\nüîÄ Splitting {name} dataset...\")\n",
    "#     train, test = df.randomSplit([1.0 - Config.TEST_RATIO, Config.TEST_RATIO], seed=Config.RANDOM_SEED)\n",
    "#     print(f\"   Train count: {train.count():,}\")\n",
    "#     print(f\"   Test count: {test.count():,}\")\n",
    "    \n",
    "#     train = checkpoint_if_enabled(train, eager=True)\n",
    "#     test = checkpoint_if_enabled(test, eager=True)\n",
    "#     return train, test\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # 4. MODEL TRAINING\n",
    "# # =============================================================================\n",
    "\n",
    "# def train_model_optimized(train_data, test_data, model_name, model_type):\n",
    "#     \"\"\"Bayesian optimization with reduced CV folds\"\"\"\n",
    "    \n",
    "#     print(f\"\\n\\tüéØ Training {model_name} ({model_type})\")\n",
    "#     print(f\"\\t   {Config.CV_FOLDS}-fold CV + {Config.BAYES_MAX_EVALS} Bayesian evals\")\n",
    "    \n",
    "#     if model_name == \"RandomForest\":\n",
    "#         space = {\n",
    "#             'numTrees': hp.choice('numTrees', [50, 100]),\n",
    "#             'maxDepth': hp.choice('maxDepth', [10, 15]),\n",
    "#             'minInstancesPerNode': hp.choice('minInstancesPerNode', [25, 50])\n",
    "#         }\n",
    "#         ModelClass = RandomForestClassifier\n",
    "#         param_map = {'numTrees': [50, 100], 'maxDepth': [10, 15], 'minInstancesPerNode': [25, 50]}\n",
    "#     else:\n",
    "#         space = {\n",
    "#             'maxIter': hp.choice('maxIter', [50, 100]),\n",
    "#             'maxDepth': hp.choice('maxDepth', [4, 6]),\n",
    "#             'stepSize': hp.uniform('stepSize', 0.05, 0.15)\n",
    "#         }\n",
    "#         ModelClass = GBTClassifier\n",
    "#         param_map = {'maxIter': [50, 100], 'maxDepth': [4, 6]}\n",
    "    \n",
    "#     def objective(params):\n",
    "#         if model_name == \"RandomForest\":\n",
    "#             model = ModelClass(\n",
    "#                 featuresCol=\"features\", labelCol=\"label\",\n",
    "#                 numTrees=int(params['numTrees']),\n",
    "#                 maxDepth=int(params['maxDepth']),\n",
    "#                 minInstancesPerNode=int(params['minInstancesPerNode']),\n",
    "#                 seed=Config.RANDOM_SEED\n",
    "#             )\n",
    "#         else:\n",
    "#             model = ModelClass(\n",
    "#                 featuresCol=\"features\", labelCol=\"label\",\n",
    "#                 maxIter=int(params['maxIter']),\n",
    "#                 maxDepth=int(params['maxDepth']),\n",
    "#                 stepSize=float(params['stepSize']),\n",
    "#                 seed=Config.RANDOM_SEED\n",
    "#             )\n",
    "        \n",
    "#         cv = CrossValidator(\n",
    "#             estimator=model,\n",
    "#             estimatorParamMaps=[{}],\n",
    "#             evaluator=BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\"),\n",
    "#             numFolds=Config.CV_FOLDS,\n",
    "#             seed=Config.RANDOM_SEED,\n",
    "#             parallelism=1\n",
    "#         )\n",
    "        \n",
    "#         cv_model = cv.fit(train_data)\n",
    "#         avg_auc = cv_model.avgMetrics[0]\n",
    "#         return {'loss': -avg_auc, 'status': STATUS_OK}\n",
    "    \n",
    "#     print(f\"\\t   Optimizing over {Config.BAYES_MAX_EVALS} iterations...\")\n",
    "#     trials = Trials()\n",
    "    \n",
    "#     best = fmin(\n",
    "#         fn=objective, space=space, algo=tpe.suggest,\n",
    "#         max_evals=Config.BAYES_MAX_EVALS, trials=trials,\n",
    "#         rstate=np.random.default_rng(Config.RANDOM_SEED),\n",
    "#         verbose=False\n",
    "#     )\n",
    "    \n",
    "#     best_params_actual = {}\n",
    "#     for k, v in best.items():\n",
    "#         if k in param_map:\n",
    "#             best_params_actual[k] = param_map[k][v]\n",
    "#         else:\n",
    "#             best_params_actual[k] = v\n",
    "    \n",
    "#     print(f\"\\t   Best params: {best_params_actual}\")\n",
    "    \n",
    "#     final_model = ModelClass(\n",
    "#         featuresCol=\"features\", labelCol=\"label\",\n",
    "#         **best_params_actual, seed=Config.RANDOM_SEED\n",
    "#     ).fit(train_data)\n",
    "    \n",
    "#     predictions = final_model.transform(test_data)\n",
    "    \n",
    "#     metrics = {\n",
    "#         \"auc_roc\": BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\").evaluate(predictions),\n",
    "#         \"accuracy\": MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\").evaluate(predictions),\n",
    "#         \"f1_score\": MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"f1\").evaluate(predictions)\n",
    "#     }\n",
    "    \n",
    "#     cv_score = -min([t['result']['loss'] for t in trials.trials])\n",
    "#     print(f\"\\t   Best CV Score: {cv_score:.4f}\")\n",
    "#     print(f\"\\t   Test AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
    "    \n",
    "#     return final_model, metrics, best_params_actual, cv_score\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # 5. MAIN PIPELINE (WORKSPACE REGISTRY LOGGING)\n",
    "# # =============================================================================\n",
    "\n",
    "# def run_complete_experiments():\n",
    "#     \"\"\"Main execution pipeline - logs to workspace registry\"\"\"\n",
    "    \n",
    "#     print(\"\\n\" + \"=\" * 80)\n",
    "#     print(\"FLIGHTMASTERS OPTIMIZED EXPERIMENTS\")\n",
    "#     print(\"Strategy: Log to Workspace Registry (bypasses MLeap issue)\")\n",
    "#     print(\"=\" * 80)\n",
    "    \n",
    "#     # Setup MLflow for workspace registry\n",
    "#     mlflow.set_tracking_uri(Config.MLFLOW_TRACKING_URI)\n",
    "#     mlflow.set_registry_uri(Config.MLFLOW_REGISTRY_URI)\n",
    "#     mlflow.set_experiment(Config.EXPERIMENT_NAME)\n",
    "    \n",
    "#     spark = SparkSession.builder.getOrCreate()\n",
    "#     setup_uc_volume(spark)\n",
    "    \n",
    "#     mlflow.end_run()\n",
    "    \n",
    "#     # === MASTER PARENT RUN ===\n",
    "#     with mlflow.start_run(run_name=\"Flight_Experiment_Master_Workspace\"):\n",
    "        \n",
    "#         # Load data\n",
    "#         print(f\"\\nüì• Loading Gold table...\")\n",
    "#         df_gold = spark.table(Config.GOLD_TABLE)\n",
    "#         df_gold = df_gold.withColumn(\"label\", col(\"label\").cast(DoubleType())).filter(\n",
    "#             (col(\"label\") == 0.0) | (col(\"label\") == 1.0)\n",
    "#         )\n",
    "#         df_gold = checkpoint_if_enabled(df_gold, eager=True)\n",
    "        \n",
    "#         train_full, test_full = df_gold.randomSplit([0.8, 0.2], seed=Config.RANDOM_SEED)\n",
    "#         train_full = checkpoint_if_enabled(train_full, eager=False)\n",
    "#         test_full = checkpoint_if_enabled(test_full, eager=False)\n",
    "\n",
    "#         # Feature selection\n",
    "#         with mlflow.start_run(run_name=\"Feature_Selection\", nested=True):\n",
    "#             orig_features, selected_indices, retention = analyze_feature_importance(\n",
    "#                 train_full, Config.TOP_K_FEATURES\n",
    "#             )\n",
    "#             mlflow.log_params({\n",
    "#                 \"step\": \"Feature_Selection\",\n",
    "#                 \"original_features\": orig_features,\n",
    "#                 \"selected_features_count\": Config.TOP_K_FEATURES\n",
    "#             })\n",
    "#             mlflow.log_metric(\"information_retained_pct\", retention)\n",
    "\n",
    "#         # Create datasets\n",
    "#         df_pre, df_in, _ = create_dual_datasets(df_gold, selected_indices)\n",
    "#         train_pre, test_pre = split_and_checkpoint(df_pre, \"Pre-Departure\")\n",
    "#         train_in, test_in = split_and_checkpoint(df_in, \"In-Flight\")\n",
    "#         results = {}\n",
    "        \n",
    "#         # Define signatures using TensorSpec (UC-compatible format)\n",
    "#         pre_dep_feature_count = train_pre.select(\"features\").first().features.size\n",
    "#         in_flight_feature_count = train_in.select(\"features\").first().features.size\n",
    "        \n",
    "#         pre_dep_input_schema = Schema([TensorSpec(type=np.dtype('float64'), shape=(-1,), name=\"features\")])\n",
    "#         in_flight_input_schema = Schema([TensorSpec(type=np.dtype('float64'), shape=(-1,), name=\"features\")])\n",
    "#         output_schema = Schema([TensorSpec(type=np.dtype('float64'), shape=(-1, 2), name=\"probability\")])\n",
    "        \n",
    "#         pre_dep_signature = ModelSignature(inputs=pre_dep_input_schema, outputs=output_schema)\n",
    "#         in_flight_signature = ModelSignature(inputs=in_flight_input_schema, outputs=output_schema)\n",
    "        \n",
    "#         print(f\"\\n‚úÖ Signatures defined. Features: Pre-Dep={pre_dep_feature_count}, In-Flight={in_flight_feature_count}\")\n",
    "\n",
    "#         # Get sample inputs\n",
    "#         sample_pre = train_pre.limit(1).select(\"features\").toPandas()\n",
    "#         sample_in = train_in.limit(1).select(\"features\").toPandas()\n",
    "        \n",
    "#         # === TRAIN & LOG MODELS ===\n",
    "        \n",
    "#         # 1. Pre-Departure Random Forest\n",
    "#         with mlflow.start_run(run_name=\"RF_Pre_Departure\", nested=True):\n",
    "#             m, metrics, p, cv = train_model_optimized(train_pre, test_pre, \"RandomForest\", \"Pre-Departure\")\n",
    "#             mlflow.log_params(p)\n",
    "#             mlflow.log_metric(\"cv_score\", cv)\n",
    "#             mlflow.log_metric(\"auc_roc\", metrics[\"auc_roc\"])\n",
    "            \n",
    "            \n",
    "#             mlflow.spark.log_model(\n",
    "#                 spark_model=m,\n",
    "#                 artifact_path=\"model\",\n",
    "#                 signature=pre_dep_signature\n",
    "#             )\n",
    "#             results[\"RF_Pre\"] = metrics\n",
    "#             print(f\"‚úÖ RF Pre-Departure logged to workspace registry.\")\n",
    "            \n",
    "#         # 2. Pre-Departure GBT\n",
    "#         with mlflow.start_run(run_name=\"GBT_Pre_Departure\", nested=True):\n",
    "#             m, metrics, p, cv = train_model_optimized(train_pre, test_pre, \"GBT\", \"Pre-Departure\")\n",
    "#             mlflow.log_params(p)\n",
    "#             mlflow.log_metric(\"cv_score\", cv)\n",
    "#             mlflow.log_metric(\"auc_roc\", metrics[\"auc_roc\"])\n",
    "            \n",
    "#             mlflow.spark.log_model(\n",
    "#                 spark_model=m,\n",
    "#                 artifact_path=\"model\",\n",
    "#                 signature=pre_dep_signature\n",
    "#             )\n",
    "#             results[\"GBT_Pre\"] = metrics\n",
    "#             print(f\"‚úÖ GBT Pre-Departure logged to workspace registry.\")\n",
    "            \n",
    "#         # 3. In-Flight Random Forest\n",
    "#         with mlflow.start_run(run_name=\"RF_In_Flight\", nested=True):\n",
    "#             m, metrics, p, cv = train_model_optimized(train_in, test_in, \"RandomForest\", \"In-Flight\")\n",
    "#             mlflow.log_params(p)\n",
    "#             mlflow.log_metric(\"cv_score\", cv)\n",
    "#             mlflow.log_metric(\"auc_roc\", metrics[\"auc_roc\"])\n",
    "            \n",
    "#             mlflow.spark.log_model(\n",
    "#                 spark_model=m,\n",
    "#                 artifact_path=\"model\",\n",
    "#                 signature=in_flight_signature\n",
    "#             )\n",
    "#             results[\"RF_In\"] = metrics\n",
    "#             print(f\"‚úÖ RF In-Flight logged to workspace registry.\")\n",
    "            \n",
    "#         # 4. In-Flight GBT\n",
    "#         with mlflow.start_run(run_name=\"GBT_In_Flight\", nested=True):\n",
    "#             m, metrics, p, cv = train_model_optimized(train_in, test_in, \"GBT\", \"In-Flight\")\n",
    "#             mlflow.log_params(p)\n",
    "#             mlflow.log_metric(\"cv_score\", cv)\n",
    "#             mlflow.log_metric(\"auc_roc\", metrics[\"auc_roc\"])\n",
    "            \n",
    "#             mlflow.spark.log_model(\n",
    "#                 spark_model=m,\n",
    "#                 artifact_path=\"model\",\n",
    "#                 signature=in_flight_signature\n",
    "#             )\n",
    "#             results[\"GBT_In\"] = metrics\n",
    "#             print(f\"‚úÖ GBT In-Flight logged to workspace registry.\")\n",
    "            \n",
    "#         # === FINAL SUMMARY ===\n",
    "#         print(\"\\n\" + \"=\" * 80)\n",
    "#         print(\"FINAL RESULTS SUMMARY\")\n",
    "#         print(\"=\" * 80)\n",
    "#         for k, v in results.items():\n",
    "#             print(f\"Model: {k:<15} | Test AUC: {v['auc_roc']:.4f}\")\n",
    "        \n",
    "#         print(\"\\n\" + \"=\" * 80)\n",
    "#         print(\"NEXT STEPS: Manual Unity Catalog Registration\")\n",
    "#         print(\"=\" * 80)\n",
    "#         print(\"Your models are now logged in the workspace registry with signatures.\")\n",
    "#         print(\"\\nTo register to Unity Catalog:\")\n",
    "#         print(\"1. Go to MLflow UI (Experiments page)\")\n",
    "#         print(\"2. Find your runs and click on each model\")\n",
    "#         print(\"3. Click 'Register Model' button\")\n",
    "#         print(f\"4. Select Unity Catalog and use format: {Config.UC_CATALOG}.{Config.UC_SCHEMA}.model_name\")\n",
    "#         print(\"\\nAlternatively, use the MLflow Client API to register programmatically\")\n",
    "#         print(\"after models are logged (example code in next message).\")\n",
    "            \n",
    "#         return results, selected_indices\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # MAIN EXECUTION\n",
    "# # =============================================================================\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    \n",
    "#     try:\n",
    "#         run_complete_experiments()\n",
    "#         print(\"\\n‚úÖ All experiments complete and MLflow runs closed successfully!\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå An error occurred during the pipeline execution: {e}\")\n",
    "#         raise e\n",
    "        \n",
    "#     finally:\n",
    "#         mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f417d51-c5e5-489c-a6c0-4ec52fe6b5f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The Notebook below is supposed to be a modified version of the one above that will register the models post creation which would allow the integration with the FlightMasters_Delay_prediction notebook that Uses the Aviation Stack API (I couldn't run it due to freetier limits being exceeded)\n",
    "\n",
    "Hopefully it works, but if it doesn't you have the code above as a refrence to build off of it and fix it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f76f3ca-98d6-4496-8cb1-87e22b956217",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n================================================================================\nFLIGHTMASTERS OPTIMIZED EXPERIMENTS\nStrategy: Log to Workspace Registry (bypasses MLeap issue)\n================================================================================\n\n================================================================================\nUNITY CATALOG VOLUME SETUP\n================================================================================\nVolume Target: workspace.default.mlflow_shared_tmp\n‚úÖ Volume already exists.\n‚úÖ Environment paths set to: /Volumes/workspace/default/mlflow_shared_tmp\n\nüì• Loading Gold table...\n\n================================================================================\nPHASE 1: FEATURE IMPORTANCE ANALYSIS\n================================================================================\n\nüìä Original features: 819\n\nüå≤ Training Random Forest for feature ranking...\n\nüìà Feature Selection Summary:\n   Original: 819 -> Selected: 40\n   Information retained: 99.3%\n\n================================================================================\nPHASE 2: CREATING DUAL DATASETS\n================================================================================\n‚úÖ dep_delay found at original index 11\n\nüîß Applying feature selection...\n\nüìã Creating Pre-Departure (removing dep_delay)...\n\nüîÄ Splitting Pre-Departure dataset...\n   Train count: 1,971,675\n   Test count: 492,304\n\nüîÄ Splitting In-Flight dataset...\n   Train count: 1,971,675\n   Test count: 492,304\n\n‚úÖ Signatures defined. Features: Pre-Dep=39, In-Flight=40\n\n\tüéØ Training RandomForest (Pre-Departure)\n\t   2-fold CV + 4 Bayesian evals\n\t   Optimizing over 4 iterations...\n\t   Best params: {'maxDepth': 15, 'minInstancesPerNode': 50, 'numTrees': 50}\n\t   Best CV Score: 0.9179\n\t   Test AUC-ROC: 0.9190\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 00:41:17 WARNING mlflow.utils.requirements_utils: Found pyspark version (4.0.0+databricks.connect.17.2.2) contains a local version label (+databricks.connect.17.2.2). MLflow logged a pip requirement for this package as 'pyspark==4.0.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n2025/12/01 00:41:22 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /local_disk0/user_tmp_data/spark-b5af1df1-361f-444e-b2fa-00/tmpcagegde_/model, flavor: spark). Fall back to return ['pyspark==4.0.0']. Set logging level to DEBUG to see the full traceback. \n2025/12/01 00:41:30 WARNING mlflow.models.model: Failed to validate serving input example {\n  \"dataframe_split\": {\n    \"data\": [\n      [\n        -1.207237017904622,\n        -0.20786040912357787,\n        -0.1496479949136231,\n        -0.20102882481404055,\n        1.9298683447944291,\n        -0.20102882481404055,\n        -0.1933867457363128,\n        7.411535467750386,\n        0.9991551867248805,\n        1.1147876967611823,\n        -0.6410853462462331,\n        0.6471551773736984,\n        -0.13119545050458828,\n        -0.14770882505072744,\n        -0.35565250909582796,\n        -0.39478474852303913,\n        -0.39478474852303913,\n        -0.18285737095773405,\n        0.4232071674389788,\n        -0.1496479949136231,\n        -0.3838396850490817,\n        -0.06625524086976506,\n        -0.4827587378138649,\n        0.39791396546674973,\n        -0.23215573208559848,\n        1.4424199933098403,\n        -1.2127812729430931,\n        -0.23208582298805658,\n        -0.4827587378138649,\n        -0.1933867457363128,\n        -0.07301138427395934,\n        -0.2026025252097402,\n        1.5349958630536578,\n        -0.5388902404985044,\n        -0.35565250909582796,\n        1.222251075509693,\n        -0.10669150686658253,\n        -0.18285737095773405,\n        -0.13173217237956733\n      ]\n    ]\n  }\n}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\nGot error: Failed to enforce schema of data '         0        1         2   ...        36        37        38\n0 -1.207237 -0.20786 -0.149648  ... -0.106692 -0.182857 -0.131732\n\n[1 rows x 39 columns]' with schema '['features': Tensor('float64', (-1,))]'. Error: Model is missing inputs ['features']. Note that there were extra inputs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88d1d5441734a1a9031ff662ca9e17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RF Pre-Departure logged to workspace registry.\n\n\tüéØ Training GBT (Pre-Departure)\n\t   2-fold CV + 4 Bayesian evals\n\t   Optimizing over 4 iterations...\n\t   Best params: {'maxDepth': 6, 'maxIter': 100, 'stepSize': np.float64(0.1313655407640288)}\n\t   Best CV Score: 0.9328\n\t   Test AUC-ROC: 0.9318\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 01:03:02 WARNING mlflow.utils.requirements_utils: Found pyspark version (4.0.0+databricks.connect.17.2.2) contains a local version label (+databricks.connect.17.2.2). MLflow logged a pip requirement for this package as 'pyspark==4.0.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n2025/12/01 01:03:04 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /local_disk0/user_tmp_data/spark-b5af1df1-361f-444e-b2fa-00/tmpohi4uphy/model, flavor: spark). Fall back to return ['pyspark==4.0.0']. Set logging level to DEBUG to see the full traceback. \n2025/12/01 01:03:12 WARNING mlflow.models.model: Failed to validate serving input example {\n  \"dataframe_split\": {\n    \"data\": [\n      [\n        -1.207237017904622,\n        -0.20786040912357787,\n        -0.1496479949136231,\n        -0.20102882481404055,\n        1.9298683447944291,\n        -0.20102882481404055,\n        -0.1933867457363128,\n        7.411535467750386,\n        0.9991551867248805,\n        1.1147876967611823,\n        -0.6410853462462331,\n        0.6471551773736984,\n        -0.13119545050458828,\n        -0.14770882505072744,\n        -0.35565250909582796,\n        -0.39478474852303913,\n        -0.39478474852303913,\n        -0.18285737095773405,\n        0.4232071674389788,\n        -0.1496479949136231,\n        -0.3838396850490817,\n        -0.06625524086976506,\n        -0.4827587378138649,\n        0.39791396546674973,\n        -0.23215573208559848,\n        1.4424199933098403,\n        -1.2127812729430931,\n        -0.23208582298805658,\n        -0.4827587378138649,\n        -0.1933867457363128,\n        -0.07301138427395934,\n        -0.2026025252097402,\n        1.5349958630536578,\n        -0.5388902404985044,\n        -0.35565250909582796,\n        1.222251075509693,\n        -0.10669150686658253,\n        -0.18285737095773405,\n        -0.13173217237956733\n      ]\n    ]\n  }\n}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\nGot error: Failed to enforce schema of data '         0        1         2   ...        36        37        38\n0 -1.207237 -0.20786 -0.149648  ... -0.106692 -0.182857 -0.131732\n\n[1 rows x 39 columns]' with schema '['features': Tensor('float64', (-1,))]'. Error: Model is missing inputs ['features']. Note that there were extra inputs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08b3f70db304e8e87dddcc2e961c344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GBT Pre-Departure logged to workspace registry.\n\n\tüéØ Training RandomForest (In-Flight)\n\t   2-fold CV + 4 Bayesian evals\n\t   Optimizing over 4 iterations...\n\t   Best params: {'maxDepth': 15, 'minInstancesPerNode': 50, 'numTrees': 50}\n\t   Best CV Score: 0.9185\n\t   Test AUC-ROC: 0.9180\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 01:25:08 WARNING mlflow.utils.requirements_utils: Found pyspark version (4.0.0+databricks.connect.17.2.2) contains a local version label (+databricks.connect.17.2.2). MLflow logged a pip requirement for this package as 'pyspark==4.0.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n2025/12/01 01:25:10 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /local_disk0/user_tmp_data/spark-b5af1df1-361f-444e-b2fa-00/tmpuod38f9f/model, flavor: spark). Fall back to return ['pyspark==4.0.0']. Set logging level to DEBUG to see the full traceback. \n2025/12/01 01:25:18 WARNING mlflow.models.model: Failed to validate serving input example {\n  \"dataframe_split\": {\n    \"data\": [\n      [\n        -1.207237017904622,\n        -0.20786040912357787,\n        0.07958174750973532,\n        -0.1496479949136231,\n        -0.20102882481404055,\n        1.9298683447944291,\n        -0.20102882481404055,\n        -0.1933867457363128,\n        7.411535467750386,\n        0.9991551867248805,\n        1.1147876967611823,\n        -0.6410853462462331,\n        0.6471551773736984,\n        -0.13119545050458828,\n        -0.14770882505072744,\n        -0.35565250909582796,\n        -0.39478474852303913,\n        -0.39478474852303913,\n        -0.18285737095773405,\n        0.4232071674389788,\n        -0.1496479949136231,\n        -0.3838396850490817,\n        -0.06625524086976506,\n        -0.4827587378138649,\n        0.39791396546674973,\n        -0.23215573208559848,\n        1.4424199933098403,\n        -1.2127812729430931,\n        -0.23208582298805658,\n        -0.4827587378138649,\n        -0.1933867457363128,\n        -0.07301138427395934,\n        -0.2026025252097402,\n        1.5349958630536578,\n        -0.5388902404985044,\n        -0.35565250909582796,\n        1.222251075509693,\n        -0.10669150686658253,\n        -0.18285737095773405,\n        -0.13173217237956733\n      ]\n    ]\n  }\n}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\nGot error: Failed to enforce schema of data '         0        1         2   ...        37        38        39\n0 -1.207237 -0.20786  0.079582  ... -0.106692 -0.182857 -0.131732\n\n[1 rows x 40 columns]' with schema '['features': Tensor('float64', (-1,))]'. Error: Model is missing inputs ['features']. Note that there were extra inputs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f639b2a622f9435a950a01c7539880ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RF In-Flight logged to workspace registry.\n\n\tüéØ Training GBT (In-Flight)\n\t   2-fold CV + 4 Bayesian evals\n\t   Optimizing over 4 iterations...\n\t   Best params: {'maxDepth': 6, 'maxIter': 100, 'stepSize': np.float64(0.1313655407640288)}\n\t   Best CV Score: 0.9328\n\t   Test AUC-ROC: 0.9326\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 01:46:21 WARNING mlflow.utils.requirements_utils: Found pyspark version (4.0.0+databricks.connect.17.2.2) contains a local version label (+databricks.connect.17.2.2). MLflow logged a pip requirement for this package as 'pyspark==4.0.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n2025/12/01 01:46:24 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /local_disk0/user_tmp_data/spark-b5af1df1-361f-444e-b2fa-00/tmplesaic77/model, flavor: spark). Fall back to return ['pyspark==4.0.0']. Set logging level to DEBUG to see the full traceback. \n2025/12/01 01:46:31 WARNING mlflow.models.model: Failed to validate serving input example {\n  \"dataframe_split\": {\n    \"data\": [\n      [\n        -1.207237017904622,\n        -0.20786040912357787,\n        0.07958174750973532,\n        -0.1496479949136231,\n        -0.20102882481404055,\n        1.9298683447944291,\n        -0.20102882481404055,\n        -0.1933867457363128,\n        7.411535467750386,\n        0.9991551867248805,\n        1.1147876967611823,\n        -0.6410853462462331,\n        0.6471551773736984,\n        -0.13119545050458828,\n        -0.14770882505072744,\n        -0.35565250909582796,\n        -0.39478474852303913,\n        -0.39478474852303913,\n        -0.18285737095773405,\n        0.4232071674389788,\n        -0.1496479949136231,\n        -0.3838396850490817,\n        -0.06625524086976506,\n        -0.4827587378138649,\n        0.39791396546674973,\n        -0.23215573208559848,\n        1.4424199933098403,\n        -1.2127812729430931,\n        -0.23208582298805658,\n        -0.4827587378138649,\n        -0.1933867457363128,\n        -0.07301138427395934,\n        -0.2026025252097402,\n        1.5349958630536578,\n        -0.5388902404985044,\n        -0.35565250909582796,\n        1.222251075509693,\n        -0.10669150686658253,\n        -0.18285737095773405,\n        -0.13173217237956733\n      ]\n    ]\n  }\n}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\nGot error: Failed to enforce schema of data '         0        1         2   ...        37        38        39\n0 -1.207237 -0.20786  0.079582  ... -0.106692 -0.182857 -0.131732\n\n[1 rows x 40 columns]' with schema '['features': Tensor('float64', (-1,))]'. Error: Model is missing inputs ['features']. Note that there were extra inputs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3af350d5f05474e967e03d1cf39ab22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GBT In-Flight logged to workspace registry.\n\n================================================================================\nFINAL RESULTS SUMMARY\n================================================================================\nModel: RF_Pre          | Test AUC: 0.9190\nModel: GBT_Pre         | Test AUC: 0.9318\nModel: RF_In           | Test AUC: 0.9180\nModel: GBT_In          | Test AUC: 0.9326\n\n================================================================================\nNEXT STEPS: Manual Unity Catalog Registration\n================================================================================\nYour models are now logged in the workspace registry with signatures.\n\nTo register to Unity Catalog:\n1. Go to MLflow UI (Experiments page)\n2. Find your runs and click on each model\n3. Click 'Register Model' button\n4. Select Unity Catalog and use format: workspace.default.model_name\n\nAlternatively, use the MLflow Client API to register programmatically\nafter models are logged (example code in next message).\n\n‚úÖ All experiments complete and MLflow runs closed successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from pyspark.ml.classification import GBTClassifier, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "# Signature imports\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, TensorSpec\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Optimized for Databricks Community Edition\"\"\"\n",
    "    \n",
    "    TOP_K_FEATURES = 40 \n",
    "    CV_FOLDS = 2\n",
    "    BAYES_MAX_EVALS = 4\n",
    "    TEST_RATIO = 0.2\n",
    "    RANDOM_SEED = 42\n",
    "    \n",
    "    GOLD_TABLE = \"default.gold_ml_features_experimental\"\n",
    "    EXPERIMENT_NAME = \"/Shared/Flightmasters_Optimized_Experiments\"\n",
    "    \n",
    "    # CRITICAL CHANGE: Use workspace registry for initial logging\n",
    "    MLFLOW_TRACKING_URI = \"databricks\"\n",
    "    MLFLOW_REGISTRY_URI = \"databricks\"  # Changed from databricks-uc\n",
    "    \n",
    "    # Model names (without UC prefix for workspace registry)\n",
    "    MODEL_RF_PRE = \"model_rf_pre\"\n",
    "    MODEL_GBT_PRE = \"model_gbt_pre\"\n",
    "    MODEL_RF_IN = \"model_rf_in\"\n",
    "    MODEL_GBT_IN = \"model_gbt_in\"\n",
    "    \n",
    "    # UC settings (for manual registration later)\n",
    "    UC_CATALOG = \"workspace\"\n",
    "    UC_SCHEMA = \"default\"\n",
    "    UC_VOLUME_NAME = \"mlflow_shared_tmp\"\n",
    "    \n",
    "    USE_CHECKPOINTING = True\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# HELPERS\n",
    "# =============================================================================\n",
    "\n",
    "def setup_uc_volume(spark):\n",
    "    \"\"\"Setup Unity Catalog Volume for artifacts\"\"\"\n",
    "    catalog = Config.UC_CATALOG\n",
    "    schema = Config.UC_SCHEMA\n",
    "    volume_name = Config.UC_VOLUME_NAME\n",
    "    \n",
    "    volume_path = f\"{catalog}.{schema}.{volume_name}\"\n",
    "    env_path = f\"/Volumes/{catalog}/{schema}/{volume_name}\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"UNITY CATALOG VOLUME SETUP\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Volume Target: {volume_path}\")\n",
    "    \n",
    "    try:\n",
    "        volume_exists = spark.sql(f\"SHOW VOLUMES IN {catalog}.{schema}\").filter(\n",
    "            col(\"volume_name\") == volume_name\n",
    "        ).count() > 0\n",
    "        \n",
    "        if not volume_exists:\n",
    "            spark.sql(f\"CREATE VOLUME {volume_path}\")\n",
    "            print(\"‚úÖ Volume created successfully.\")\n",
    "        else:\n",
    "            print(\"‚úÖ Volume already exists.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  WARNING: Could not check/create volume: {e}\")\n",
    "        pass\n",
    "        \n",
    "    os.environ['MLFLOW_DFS_TMP'] = env_path\n",
    "    os.environ['SPARKML_TEMP_DFS_PATH'] = env_path\n",
    "    \n",
    "    print(f\"‚úÖ Environment paths set to: {env_path}\")\n",
    "    return volume_path\n",
    "\n",
    "\n",
    "def create_safe_vector_slicer(indices_to_keep):\n",
    "    \"\"\"Create UDF to slice vectors\"\"\"\n",
    "    indices_list = list(indices_to_keep)\n",
    "    \n",
    "    @udf(returnType=VectorUDT())\n",
    "    def safe_slicer(features):\n",
    "        if features is None: \n",
    "            return None\n",
    "        max_idx = features.size - 1\n",
    "        selected_values = [float(features[i]) for i in indices_list if i <= max_idx]\n",
    "        return Vectors.dense(selected_values)\n",
    "    \n",
    "    return safe_slicer\n",
    "\n",
    "\n",
    "def checkpoint_if_enabled(df, eager=True):\n",
    "    \"\"\"Checkpoint data to prevent OOM\"\"\"\n",
    "    if Config.USE_CHECKPOINTING:\n",
    "        return df.localCheckpoint(eager=eager)\n",
    "    return df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 1. FEATURE IMPORTANCE\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_feature_importance(train_data, top_k):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PHASE 1: FEATURE IMPORTANCE ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    sample = train_data.select(\"features\").first()\n",
    "    if not sample:\n",
    "        raise ValueError(\"Training data is empty or features column is missing.\")\n",
    "        \n",
    "    total_features = sample.features.size\n",
    "    print(f\"\\nüìä Original features: {total_features}\")\n",
    "    \n",
    "    print(\"\\nüå≤ Training Random Forest for feature ranking...\")\n",
    "    rf = RandomForestClassifier(\n",
    "        featuresCol=\"features\", labelCol=\"label\",\n",
    "        numTrees=30, maxDepth=8, seed=Config.RANDOM_SEED\n",
    "    )\n",
    "    \n",
    "    rf_model = rf.fit(train_data)\n",
    "    importances = rf_model.featureImportances.toArray()\n",
    "    \n",
    "    top_k_indices = np.argsort(importances)[-top_k:][::-1]\n",
    "    top_k_scores = importances[top_k_indices]\n",
    "    \n",
    "    selected_importance = np.sum(top_k_scores)\n",
    "    total_importance = np.sum(importances)\n",
    "    retention = (selected_importance / total_importance) * 100\n",
    "    \n",
    "    print(f\"\\nüìà Feature Selection Summary:\")\n",
    "    print(f\"   Original: {total_features} -> Selected: {top_k}\")\n",
    "    print(f\"   Information retained: {retention:.1f}%\")\n",
    "    \n",
    "    return total_features, top_k_indices.tolist(), retention\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. CREATE DUAL DATASETS\n",
    "# =============================================================================\n",
    "\n",
    "def create_dual_datasets(df_gold, selected_indices, dep_delay_orig_index=11):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PHASE 2: CREATING DUAL DATASETS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    dep_delay_in_selected = dep_delay_orig_index in selected_indices\n",
    "    if dep_delay_in_selected: \n",
    "        print(f\"‚úÖ dep_delay found at original index {dep_delay_orig_index}\")\n",
    "    else: \n",
    "        print(f\"‚ö†Ô∏è  dep_delay (index {dep_delay_orig_index}) not in top-K\")\n",
    "    \n",
    "    print(f\"\\nüîß Applying feature selection...\")\n",
    "    slicer_udf = create_safe_vector_slicer(selected_indices)\n",
    "    df_selected = df_gold.withColumn(\"features\", slicer_udf(col(\"features\"))).select(\"features\", \"label\")\n",
    "    df_selected = df_selected.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
    "    df_selected = checkpoint_if_enabled(df_selected)\n",
    "    \n",
    "    if dep_delay_in_selected:\n",
    "        print(f\"\\nüìã Creating Pre-Departure (removing dep_delay)...\")\n",
    "        dep_delay_new_index = selected_indices.index(dep_delay_orig_index)\n",
    "        pre_dep_indices = [i for i in range(len(selected_indices)) if i != dep_delay_new_index]\n",
    "        pre_dep_slicer = create_safe_vector_slicer(pre_dep_indices)\n",
    "        df_pre_dep = df_selected.withColumn(\"features\", pre_dep_slicer(col(\"features\"))).select(\"features\", \"label\")\n",
    "    else:\n",
    "        df_pre_dep = df_selected\n",
    "    \n",
    "    df_in_flight = df_selected\n",
    "    \n",
    "    df_pre_dep = checkpoint_if_enabled(df_pre_dep, eager=False)\n",
    "    df_in_flight = checkpoint_if_enabled(df_in_flight, eager=False)\n",
    "    \n",
    "    return df_pre_dep, df_in_flight, dep_delay_in_selected\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3. TRAIN/TEST SPLIT\n",
    "# =============================================================================\n",
    "\n",
    "def split_and_checkpoint(df, name):\n",
    "    print(f\"\\nüîÄ Splitting {name} dataset...\")\n",
    "    train, test = df.randomSplit([1.0 - Config.TEST_RATIO, Config.TEST_RATIO], seed=Config.RANDOM_SEED)\n",
    "    print(f\"   Train count: {train.count():,}\")\n",
    "    print(f\"   Test count: {test.count():,}\")\n",
    "    \n",
    "    train = checkpoint_if_enabled(train, eager=True)\n",
    "    test = checkpoint_if_enabled(test, eager=True)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. MODEL TRAINING\n",
    "# =============================================================================\n",
    "\n",
    "def train_model_optimized(train_data, test_data, model_name, model_type):\n",
    "    \"\"\"Bayesian optimization with reduced CV folds\"\"\"\n",
    "    \n",
    "    print(f\"\\n\\tüéØ Training {model_name} ({model_type})\")\n",
    "    print(f\"\\t   {Config.CV_FOLDS}-fold CV + {Config.BAYES_MAX_EVALS} Bayesian evals\")\n",
    "    \n",
    "    if model_name == \"RandomForest\":\n",
    "        space = {\n",
    "            'numTrees': hp.choice('numTrees', [50, 100]),\n",
    "            'maxDepth': hp.choice('maxDepth', [10, 15]),\n",
    "            'minInstancesPerNode': hp.choice('minInstancesPerNode', [25, 50])\n",
    "        }\n",
    "        ModelClass = RandomForestClassifier\n",
    "        param_map = {'numTrees': [50, 100], 'maxDepth': [10, 15], 'minInstancesPerNode': [25, 50]}\n",
    "    else:\n",
    "        space = {\n",
    "            'maxIter': hp.choice('maxIter', [50, 100]),\n",
    "            'maxDepth': hp.choice('maxDepth', [4, 6]),\n",
    "            'stepSize': hp.uniform('stepSize', 0.05, 0.15)\n",
    "        }\n",
    "        ModelClass = GBTClassifier\n",
    "        param_map = {'maxIter': [50, 100], 'maxDepth': [4, 6]}\n",
    "    \n",
    "    def objective(params):\n",
    "        if model_name == \"RandomForest\":\n",
    "            model = ModelClass(\n",
    "                featuresCol=\"features\", labelCol=\"label\",\n",
    "                numTrees=int(params['numTrees']),\n",
    "                maxDepth=int(params['maxDepth']),\n",
    "                minInstancesPerNode=int(params['minInstancesPerNode']),\n",
    "                seed=Config.RANDOM_SEED\n",
    "            )\n",
    "        else:\n",
    "            model = ModelClass(\n",
    "                featuresCol=\"features\", labelCol=\"label\",\n",
    "                maxIter=int(params['maxIter']),\n",
    "                maxDepth=int(params['maxDepth']),\n",
    "                stepSize=float(params['stepSize']),\n",
    "                seed=Config.RANDOM_SEED\n",
    "            )\n",
    "        \n",
    "        cv = CrossValidator(\n",
    "            estimator=model,\n",
    "            estimatorParamMaps=[{}],\n",
    "            evaluator=BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\"),\n",
    "            numFolds=Config.CV_FOLDS,\n",
    "            seed=Config.RANDOM_SEED,\n",
    "            parallelism=1\n",
    "        )\n",
    "        \n",
    "        cv_model = cv.fit(train_data)\n",
    "        avg_auc = cv_model.avgMetrics[0]\n",
    "        return {'loss': -avg_auc, 'status': STATUS_OK}\n",
    "    \n",
    "    print(f\"\\t   Optimizing over {Config.BAYES_MAX_EVALS} iterations...\")\n",
    "    trials = Trials()\n",
    "    \n",
    "    best = fmin(\n",
    "        fn=objective, space=space, algo=tpe.suggest,\n",
    "        max_evals=Config.BAYES_MAX_EVALS, trials=trials,\n",
    "        rstate=np.random.default_rng(Config.RANDOM_SEED),\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    best_params_actual = {}\n",
    "    for k, v in best.items():\n",
    "        if k in param_map:\n",
    "            best_params_actual[k] = param_map[k][v]\n",
    "        else:\n",
    "            best_params_actual[k] = v\n",
    "    \n",
    "    print(f\"\\t   Best params: {best_params_actual}\")\n",
    "    \n",
    "    final_model = ModelClass(\n",
    "        featuresCol=\"features\", labelCol=\"label\",\n",
    "        **best_params_actual, seed=Config.RANDOM_SEED\n",
    "    ).fit(train_data)\n",
    "    \n",
    "    predictions = final_model.transform(test_data)\n",
    "    \n",
    "    metrics = {\n",
    "        \"auc_roc\": BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\").evaluate(predictions),\n",
    "        \"accuracy\": MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\").evaluate(predictions),\n",
    "        \"f1_score\": MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"f1\").evaluate(predictions)\n",
    "    }\n",
    "    \n",
    "    cv_score = -min([t['result']['loss'] for t in trials.trials])\n",
    "    print(f\"\\t   Best CV Score: {cv_score:.4f}\")\n",
    "    print(f\"\\t   Test AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
    "    \n",
    "    return final_model, metrics, best_params_actual, cv_score\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5. MAIN PIPELINE (WORKSPACE REGISTRY LOGGING)\n",
    "# =============================================================================\n",
    "\n",
    "def run_complete_experiments():\n",
    "    \"\"\"Main execution pipeline - logs to workspace registry\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FLIGHTMASTERS OPTIMIZED EXPERIMENTS\")\n",
    "    print(\"Strategy: Log to Workspace Registry (bypasses MLeap issue)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Setup MLflow for workspace registry\n",
    "    mlflow.set_tracking_uri(Config.MLFLOW_TRACKING_URI)\n",
    "    mlflow.set_registry_uri(Config.MLFLOW_REGISTRY_URI)\n",
    "    mlflow.set_experiment(Config.EXPERIMENT_NAME)\n",
    "    \n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    setup_uc_volume(spark)\n",
    "    \n",
    "    mlflow.end_run()\n",
    "    \n",
    "    # === MASTER PARENT RUN ===\n",
    "    with mlflow.start_run(run_name=\"Flight_Experiment_Master_Workspace\"):\n",
    "        \n",
    "        # Load data\n",
    "        print(f\"\\nüì• Loading Gold table...\")\n",
    "        df_gold = spark.table(Config.GOLD_TABLE)\n",
    "        df_gold = df_gold.withColumn(\"label\", col(\"label\").cast(DoubleType())).filter(\n",
    "            (col(\"label\") == 0.0) | (col(\"label\") == 1.0)\n",
    "        )\n",
    "        df_gold = checkpoint_if_enabled(df_gold, eager=True)\n",
    "        \n",
    "        train_full, test_full = df_gold.randomSplit([0.8, 0.2], seed=Config.RANDOM_SEED)\n",
    "        train_full = checkpoint_if_enabled(train_full, eager=False)\n",
    "        test_full = checkpoint_if_enabled(test_full, eager=False)\n",
    "\n",
    "        # Feature selection\n",
    "        with mlflow.start_run(run_name=\"Feature_Selection\", nested=True):\n",
    "            orig_features, selected_indices, retention = analyze_feature_importance(\n",
    "                train_full, Config.TOP_K_FEATURES\n",
    "            )\n",
    "            mlflow.log_params({\n",
    "                \"step\": \"Feature_Selection\",\n",
    "                \"original_features\": orig_features,\n",
    "                \"selected_features_count\": Config.TOP_K_FEATURES\n",
    "            })\n",
    "            mlflow.log_metric(\"information_retained_pct\", retention)\n",
    "\n",
    "            # === CRITICAL FIX: LOG SELECTED INDICES ARTIFACT ===\n",
    "            temp_file = \"selected_feature_indices.txt\"\n",
    "            with open(temp_file, \"w\") as f:\n",
    "                # Write indices as a comma-separated list\n",
    "                f.write(\",\".join(map(str, selected_indices)))\n",
    "                \n",
    "            mlflow.log_artifact(temp_file)\n",
    "            os.remove(temp_file) # Clean up the local file\n",
    "\n",
    "        # Create datasets\n",
    "        df_pre, df_in, _ = create_dual_datasets(df_gold, selected_indices)\n",
    "        train_pre, test_pre = split_and_checkpoint(df_pre, \"Pre-Departure\")\n",
    "        train_in, test_in = split_and_checkpoint(df_in, \"In-Flight\")\n",
    "        results = {}\n",
    "        \n",
    "        # Define signatures using TensorSpec (UC-compatible format)\n",
    "        pre_dep_feature_count = train_pre.select(\"features\").first().features.size\n",
    "        in_flight_feature_count = train_in.select(\"features\").first().features.size\n",
    "        \n",
    "        pre_dep_input_schema = Schema([TensorSpec(type=np.dtype('float64'), shape=(-1,), name=\"features\")])\n",
    "        in_flight_input_schema = Schema([TensorSpec(type=np.dtype('float64'), shape=(-1,), name=\"features\")])\n",
    "        output_schema = Schema([TensorSpec(type=np.dtype('float64'), shape=(-1, 2), name=\"probability\")])\n",
    "        \n",
    "        pre_dep_signature = ModelSignature(inputs=pre_dep_input_schema, outputs=output_schema)\n",
    "        in_flight_signature = ModelSignature(inputs=in_flight_input_schema, outputs=output_schema)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Signatures defined. Features: Pre-Dep={pre_dep_feature_count}, In-Flight={in_flight_feature_count}\")\n",
    "\n",
    "        # Get sample inputs - convert DenseVector to list/array for JSON serialization\n",
    "        sample_pre_row = train_pre.limit(1).select(\"features\").collect()[0]\n",
    "        sample_pre = pd.DataFrame([sample_pre_row.features.toArray()])\n",
    "        \n",
    "        sample_in_row = train_in.limit(1).select(\"features\").collect()[0]\n",
    "        sample_in = pd.DataFrame([sample_in_row.features.toArray()])\n",
    "        \n",
    "        # === TRAIN & LOG MODELS ===\n",
    "        \n",
    "        # 1. Pre-Departure Random Forest\n",
    "        with mlflow.start_run(run_name=\"RF_Pre_Departure\", nested=True):\n",
    "            m, metrics, p, cv = train_model_optimized(train_pre, test_pre, \"RandomForest\", \"Pre-Departure\")\n",
    "            mlflow.log_params(p)\n",
    "            mlflow.log_metric(\"cv_score\", cv)\n",
    "            mlflow.log_metric(\"auc_roc\", metrics[\"auc_roc\"])\n",
    "            \n",
    "            # CRITICAL FIX: Log WITHOUT registered_model_name parameter\n",
    "            mlflow.spark.log_model(\n",
    "                spark_model=m,\n",
    "                artifact_path=\"model\",\n",
    "                signature=pre_dep_signature,\n",
    "                input_example=sample_pre\n",
    "            )\n",
    "            results[\"RF_Pre\"] = metrics\n",
    "            print(f\"‚úÖ RF Pre-Departure logged to workspace registry.\")\n",
    "            \n",
    "        # 2. Pre-Departure GBT\n",
    "        with mlflow.start_run(run_name=\"GBT_Pre_Departure\", nested=True):\n",
    "            m, metrics, p, cv = train_model_optimized(train_pre, test_pre, \"GBT\", \"Pre-Departure\")\n",
    "            mlflow.log_params(p)\n",
    "            mlflow.log_metric(\"cv_score\", cv)\n",
    "            mlflow.log_metric(\"auc_roc\", metrics[\"auc_roc\"])\n",
    "            \n",
    "            mlflow.spark.log_model(\n",
    "                spark_model=m,\n",
    "                artifact_path=\"model\",\n",
    "                signature=pre_dep_signature,\n",
    "                input_example=sample_pre\n",
    "            )\n",
    "            results[\"GBT_Pre\"] = metrics\n",
    "            print(f\"‚úÖ GBT Pre-Departure logged to workspace registry.\")\n",
    "            \n",
    "        # 3. In-Flight Random Forest\n",
    "        with mlflow.start_run(run_name=\"RF_In_Flight\", nested=True):\n",
    "            m, metrics, p, cv = train_model_optimized(train_in, test_in, \"RandomForest\", \"In-Flight\")\n",
    "            mlflow.log_params(p)\n",
    "            mlflow.log_metric(\"cv_score\", cv)\n",
    "            mlflow.log_metric(\"auc_roc\", metrics[\"auc_roc\"])\n",
    "            \n",
    "            mlflow.spark.log_model(\n",
    "                spark_model=m,\n",
    "                artifact_path=\"model\",\n",
    "                signature=in_flight_signature,\n",
    "                input_example=sample_in\n",
    "            )\n",
    "            results[\"RF_In\"] = metrics\n",
    "            print(f\"‚úÖ RF In-Flight logged to workspace registry.\")\n",
    "            \n",
    "        # 4. In-Flight GBT\n",
    "        with mlflow.start_run(run_name=\"GBT_In_Flight\", nested=True):\n",
    "            m, metrics, p, cv = train_model_optimized(train_in, test_in, \"GBT\", \"In-Flight\")\n",
    "            mlflow.log_params(p)\n",
    "            mlflow.log_metric(\"cv_score\", cv)\n",
    "            mlflow.log_metric(\"auc_roc\", metrics[\"auc_roc\"])\n",
    "            \n",
    "            mlflow.spark.log_model(\n",
    "                spark_model=m,\n",
    "                artifact_path=\"model\",\n",
    "                signature=in_flight_signature,\n",
    "                input_example=sample_in\n",
    "            )\n",
    "            results[\"GBT_In\"] = metrics\n",
    "            print(f\"‚úÖ GBT In-Flight logged to workspace registry.\")\n",
    "            \n",
    "        # === FINAL SUMMARY ===\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"FINAL RESULTS SUMMARY\")\n",
    "        print(\"=\" * 80)\n",
    "        for k, v in results.items():\n",
    "            print(f\"Model: {k:<15} | Test AUC: {v['auc_roc']:.4f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"NEXT STEPS: Manual Unity Catalog Registration\")\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your models are now logged in the workspace registry with signatures.\")\n",
    "        print(\"\\nTo register to Unity Catalog:\")\n",
    "        print(\"1. Go to MLflow UI (Experiments page)\")\n",
    "        print(\"2. Find your runs and click on each model\")\n",
    "        print(\"3. Click 'Register Model' button\")\n",
    "        print(f\"4. Select Unity Catalog and use format: {Config.UC_CATALOG}.{Config.UC_SCHEMA}.model_name\")\n",
    "        print(\"\\nAlternatively, use the MLflow Client API to register programmatically\")\n",
    "        print(\"after models are logged (example code in next message).\")\n",
    "            \n",
    "        return results, selected_indices\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    try:\n",
    "        run_complete_experiments()\n",
    "        print(\"\\n‚úÖ All experiments complete and MLflow runs closed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An error occurred during the pipeline execution: {e}\")\n",
    "        raise e\n",
    "        \n",
    "    finally:\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a94f5cc-f6d8-4153-ab68-d0faf5cb8363",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Useful Information:\n",
    "\n",
    "You can find the ML models and information regarding feature selection in the Experiments tab on the left hand side.\n",
    "\n",
    "You can see the indexs of what features were used for training in the Artifacts tab of Feature Engineering within experiments (indexes refrence the Gold table).\n",
    "\n",
    "Once done head on to Flightmasters_Delay_Prediction notebook where you will need to fix and run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cdb58c3-89c1-4f87-9d05-0bc960c94e16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Advanced_Experiment_Tracking_and_Models",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
