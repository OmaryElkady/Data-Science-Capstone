# FLIGHT DELAY PREDICTION - KAGGLE NOTEBOOK CODE
# Copy and paste each cell into your Kaggle notebook

# =============================================================================
# CELL 1: Install Packages
# =============================================================================

%pip install -q torch tensorflow xgboost lightgbm
print("‚úÖ All packages installed successfully!")

# =============================================================================
# CELL 2: Import Libraries
# =============================================================================

import pandas as pd
import numpy as np
import joblib
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import (
    classification_report, confusion_matrix, accuracy_score,
    precision_score, recall_score, f1_score, roc_auc_score, roc_curve
)
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import GridSearchCV
import warnings
warnings.filterwarnings('ignore')

# GPU/TPU detection and setup
import os
import torch
import tensorflow as tf

# Set style for better plots
plt.style.use('default')
sns.set_palette("husl")

print("‚úÖ Libraries imported successfully!")

# =============================================================================
# CELL 3: GPU/TPU Detection and Setup
# =============================================================================

def setup_gpu_acceleration():
    """
    Set up GPU acceleration for training.
    """
    print("=== GPU/TPU ACCELERATION SETUP ===")
    
    # Check for TPU
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('üöÄ Running on TPU:', tpu.master())
        tf.config.experimental_connect_to_cluster(tpu)
        tf.tpu.experimental.initialize_tpu_system(tpu)
        tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)
        print(f'TPU devices: {tpu_strategy.num_replicas_in_sync}')
        return 'tpu', tpu_strategy
    except:
        print('‚ùå TPU not available')
    
    # Check for GPU
    if torch.cuda.is_available():
        print(f'üöÄ GPU available: {torch.cuda.get_device_name(0)}')
        print(f'GPU count: {torch.cuda.device_count()}')
        print(f'Current GPU: {torch.cuda.current_device()}')
        return 'gpu', torch.cuda.device_count()
    
    # Check TensorFlow GPU
    if tf.config.list_physical_devices('GPU'):
        gpus = tf.config.list_physical_devices('GPU')
        print(f'üöÄ TensorFlow GPU devices: {len(gpus)}')
        for gpu in gpus:
            print(f'  {gpu}')
        return 'gpu', len(gpus)
    
    print('‚ö†Ô∏è  No GPU/TPU available, using CPU')
    return 'cpu', 1

# Initialize acceleration
device_type, device_count = setup_gpu_acceleration()
print(f"\nüéØ Using: {device_type.upper()} with {device_count} device(s)")

# =============================================================================
# CELL 4: Load Data
# =============================================================================

# Load preprocessed data
print("üìä Loading preprocessed data...")

# Load the numpy files (adjust path based on your dataset name)
X_train = np.load('/kaggle/input/flight-delay-data/X_train.npy')
X_test = np.load('/kaggle/input/flight-delay-data/X_test.npy')
y_train = np.load('/kaggle/input/flight-delay-data/y_train.npy')
y_test = np.load('/kaggle/input/flight-delay-data/y_test.npy')

print(f"‚úÖ Data loaded successfully!")
print(f"üìà Data shapes:")
print(f"  X_train: {X_train.shape}")
print(f"  X_test: {X_test.shape}")
print(f"  y_train: {y_train.shape}")
print(f"  y_test: {y_test.shape}")
print(f"  Positive class rate: {y_train.mean():.3f}")
print(f"  Total samples: {len(X_train) + len(X_test):,}")

# =============================================================================
# CELL 5: Train Decision Tree with Hyperparameter Tuning
# =============================================================================

print("üå≥ TRAINING DECISION TREE WITH GPU ACCELERATION")

# Determine optimal n_jobs based on device type
if device_type == 'tpu':
    n_jobs = device_count * 8  # TPU has many cores
elif device_type == 'gpu':
    n_jobs = device_count * 4  # GPU with multiple cores
else:
    n_jobs = -1  # Use all CPU cores

print(f"‚ö° Using {n_jobs} parallel jobs for grid search...")

# Define parameter grid
param_grid = {
    'max_depth': [10, 15, 20],
    'min_samples_split': [50, 100, 200],
    'min_samples_leaf': [25, 50, 100],
    'max_features': ['sqrt', 'log2']
}

# Create base model
dt_base = DecisionTreeClassifier(
    random_state=42,
    class_weight='balanced'
)

# Grid search with cross-validation
print("üîç Performing grid search...")
grid_search = GridSearchCV(
    dt_base, 
    param_grid, 
    cv=3, 
    scoring='f1', 
    n_jobs=n_jobs, 
    verbose=1
)

grid_search.fit(X_train, y_train)

print(f"\nüéØ Best parameters: {grid_search.best_params_}")
print(f"üèÜ Best CV score: {grid_search.best_score_:.4f}")

# Get best model
best_dt_model = grid_search.best_estimator_

# Make predictions
dt_pred = best_dt_model.predict(X_test)
dt_proba = best_dt_model.predict_proba(X_test)[:, 1]

# Calculate metrics
dt_accuracy = accuracy_score(y_test, dt_pred)
dt_precision = precision_score(y_test, dt_pred)
dt_recall = recall_score(y_test, dt_pred)
dt_f1 = f1_score(y_test, dt_pred)
dt_auc = roc_auc_score(y_test, dt_proba)

print(f"\nüìä Decision Tree Results:")
print(f"  Accuracy:  {dt_accuracy:.4f}")
print(f"  Precision: {dt_precision:.4f}")
print(f"  Recall:    {dt_recall:.4f}")
print(f"  F1-Score:  {dt_f1:.4f}")
print(f"  AUC-ROC:   {dt_auc:.4f}")

# =============================================================================
# CELL 6: Train Random Forest with GPU Optimization
# =============================================================================

print("\nüå≤ TRAINING RANDOM FOREST WITH GPU ACCELERATION")

rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=15,
    min_samples_split=50,
    min_samples_leaf=25,
    class_weight='balanced',
    random_state=42,
    n_jobs=n_jobs  # GPU parallel processing
)

print("üèÉ Training Random Forest...")
rf_model.fit(X_train, y_train)

# Make predictions
rf_pred = rf_model.predict(X_test)
rf_proba = rf_model.predict_proba(X_test)[:, 1]

# Calculate metrics
rf_accuracy = accuracy_score(y_test, rf_pred)
rf_precision = precision_score(y_test, rf_pred)
rf_recall = recall_score(y_test, rf_pred)
rf_f1 = f1_score(y_test, rf_pred)
rf_auc = roc_auc_score(y_test, rf_proba)

print(f"\nüìä Random Forest Results:")
print(f"  Accuracy:  {rf_accuracy:.4f}")
print(f"  Precision: {rf_precision:.4f}")
print(f"  Recall:    {rf_recall:.4f}")
print(f"  F1-Score:  {rf_f1:.4f}")
print(f"  AUC-ROC:   {rf_auc:.4f}")

# =============================================================================
# CELL 7: Train Gradient Boosting
# =============================================================================

print("\nüöÄ TRAINING GRADIENT BOOSTING")

gb_model = GradientBoostingClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    random_state=42
)

print("üèÉ Training Gradient Boosting...")
gb_model.fit(X_train, y_train)

# Make predictions
gb_pred = gb_model.predict(X_test)
gb_proba = gb_model.predict_proba(X_test)[:, 1]

# Calculate metrics
gb_accuracy = accuracy_score(y_test, gb_pred)
gb_precision = precision_score(y_test, gb_pred)
gb_recall = recall_score(y_test, gb_pred)
gb_f1 = f1_score(y_test, gb_pred)
gb_auc = roc_auc_score(y_test, gb_proba)

print(f"\nüìä Gradient Boosting Results:")
print(f"  Accuracy:  {gb_accuracy:.4f}")
print(f"  Precision: {gb_precision:.4f}")
print(f"  Recall:    {gb_recall:.4f}")
print(f"  F1-Score:  {gb_f1:.4f}")
print(f"  AUC-ROC:   {gb_auc:.4f}")

# =============================================================================
# CELL 8: Model Performance Comparison
# =============================================================================

print("\nüìä MODEL PERFORMANCE COMPARISON")

# Create comparison dataframe
results_df = pd.DataFrame({
    'Model': ['Decision Tree', 'Random Forest', 'Gradient Boosting'],
    'Accuracy': [dt_accuracy, rf_accuracy, gb_accuracy],
    'Precision': [dt_precision, rf_precision, gb_precision],
    'Recall': [dt_recall, rf_recall, gb_recall],
    'F1-Score': [dt_f1, rf_f1, gb_f1],
    'AUC-ROC': [dt_auc, rf_auc, gb_auc]
})

print("\nüèÜ Final Results Summary:")
print(results_df.round(4))

# Find best model for each metric
print("\nü•á Best Model by Metric:")
for metric in ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']:
    best_idx = results_df[metric].idxmax()
    best_model = results_df.loc[best_idx, 'Model']
    best_score = results_df.loc[best_idx, metric]
    print(f"  {metric}: {best_model} ({best_score:.4f})")

# =============================================================================
# CELL 9: Performance Visualizations
# =============================================================================

print("\nüìà Creating Performance Visualizations...")

# Model comparison bar chart
fig, axes = plt.subplots(2, 3, figsize=(18, 12))
axes = axes.flatten()

metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']
colors = ['skyblue', 'lightgreen', 'lightcoral']

for i, metric in enumerate(metrics):
    ax = axes[i]
    bars = ax.bar(results_df['Model'], results_df[metric], color=colors)
    ax.set_title(f'{metric} Comparison', fontsize=14, fontweight='bold')
    ax.set_ylabel(metric)
    ax.set_ylim(0, 1)
    
    # Add value labels on bars
    for bar, value in zip(bars, results_df[metric]):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{value:.3f}', ha='center', va='bottom', fontweight='bold')

# Overall performance status
axes[5].text(0.5, 0.5, 'GPU Accelerated\nTraining Complete!', 
             ha='center', va='center', fontsize=16, fontweight='bold',
             transform=axes[5].transAxes)
axes[5].set_title('Training Status', fontsize=14, fontweight='bold')
axes[5].axis('off')

plt.suptitle('Flight Delay Prediction - Model Performance Comparison (GPU Accelerated)', 
             fontsize=16, fontweight='bold')
plt.tight_layout()
plt.show()

# =============================================================================
# CELL 10: ROC Curves Comparison
# =============================================================================

# ROC Curves Comparison
plt.figure(figsize=(10, 8))

# Plot ROC curves for all models
models_data = [
    ('Decision Tree', dt_proba, dt_auc),
    ('Random Forest', rf_proba, rf_auc),
    ('Gradient Boosting', gb_proba, gb_auc)
]

for model_name, proba, auc in models_data:
    fpr, tpr, _ = roc_curve(y_test, proba)
    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.3f})', linewidth=2)

# Plot random classifier
plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier', alpha=0.5)

plt.xlabel('False Positive Rate', fontsize=12)
plt.ylabel('True Positive Rate', fontsize=12)
plt.title('ROC Curves Comparison - Flight Delay Prediction', fontsize=14, fontweight='bold')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# =============================================================================
# CELL 11: Feature Importance Analysis
# =============================================================================

print("\nüîç FEATURE IMPORTANCE ANALYSIS")

importances = rf_model.feature_importances_
feature_names = [f"Feature_{i}" for i in range(len(importances))]

# Create importance dataframe
importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': importances
}).sort_values('importance', ascending=False)

print("\nüèÜ Top 15 Most Important Features:")
print(importance_df.head(15))

# Plot feature importance
plt.figure(figsize=(12, 8))
top_features = importance_df.head(20)
sns.barplot(data=top_features, x='importance', y='feature')
plt.title('Top 20 Feature Importances - Random Forest', fontsize=14, fontweight='bold')
plt.xlabel('Importance')
plt.tight_layout()
plt.show()

# =============================================================================
# CELL 12: Final Summary
# =============================================================================

print("\n" + "="*60)
print("üéâ FLIGHT DELAY PREDICTION - TRAINING COMPLETE!")
print("="*60)

print(f"\nüöÄ Device Used: {device_type.upper()} with {device_count} device(s)")
print(f"üìä Dataset: {X_train.shape[0]:,} training samples, {X_test.shape[0]:,} test samples")
print(f"üéØ Target: 15+ minute delays ({y_train.mean():.1%} positive class)")

print(f"\nüèÜ BEST MODEL PERFORMANCE:")
best_model_row = results_df.loc[results_df['F1-Score'].idxmax()]
for metric in ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']:
    print(f"  {metric}: {best_model_row[metric]:.4f}")

print(f"\n‚úÖ All models trained successfully with GPU acceleration!")
print(f"üìà Visualizations and analysis complete.")

# =============================================================================
# END OF NOTEBOOK CODE
# =============================================================================
