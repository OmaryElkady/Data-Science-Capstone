{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c50318f-76e7-4ee4-b8f2-a3cddccf0603",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Prerequistes:\n",
    "\n",
    "You wil need to create a Secrets scope and key within databricks-CLI which can be done from a bash or powershell terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8817e4f2-f563-47fd-8d02-edeaaf61f757",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "040cefac-b190-4a57-b475-664e29bcbb7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession \n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "API_KEY = dbutils.secrets.get(scope=\"my-secrets\", key=\"aviation_stack_api\") #change this to your scope and key\n",
    "BASE_URL = \"https://api.aviationstack.com/v1\"\n",
    "\n",
    "# --- 2. GET USER INPUT FROM WIDGETS (Unchanged) ---\n",
    "# ... (Widget code from original notebook remains here) ...\n",
    "dbutils.widgets.removeAll() # Recommended practice to clear old widgets before defining new ones\n",
    "dbutils.widgets.text(name=\"p_flight_icao\", defaultValue=\"DAL1234\", label=\"Flight ICAO Code\")\n",
    "dbutils.widgets.text(name=\"p_departure_date\", defaultValue=\"2025-11-30\", label=\"Departure Date (YYYY-MM-DD)\")\n",
    "dbutils.widgets.dropdown(name=\"p_current_stage\", choices=[\"Pre-Departure\", \"In-Flight\"], defaultValue=\"Pre-Departure\", label=\"Current Prediction Stage\")\n",
    "\n",
    "p_flight_icao = dbutils.widgets.get(\"p_flight_icao\")\n",
    "p_departure_date = dbutils.widgets.get(\"p_departure_date\")\n",
    "p_current_stage = dbutils.widgets.get(\"p_current_stage\")\n",
    "CLEAN_FLIGHT_CODE = p_flight_icao.replace(\" \", \"\").upper()\n",
    "\n",
    "print(f\"Fetching data for flight code: {CLEAN_FLIGHT_CODE} on date: {p_departure_date}\")\n",
    "# ---------------------------------------------\n",
    "\n",
    "\n",
    "# --- 3. DYNAMIC CONFIGURATION (NEW: Using data from Gold Table and Selection) ---\n",
    "\n",
    "# 1. ACTUAL SELECTED FEATURES (Ordered by importance/index from selected_indices.csv)\n",
    "# Indices have been mapped to their original feature name or generic OHE placeholder.\n",
    "IN_FLIGHT_FEATURES = [\n",
    "    'dep_delay', 'dep_hour', 'arr_hour', 'OHE_DIMENSION_47', 'OHE_DIMENSION_23', \n",
    "    'OHE_DIMENSION_817', 'OHE_DIMENSION_42', 'OHE_DIMENSION_43', 'OHE_DIMENSION_451', \n",
    "    'week_of_year', 'flight_month', 'OHE_DIMENSION_814', 'flight_year', \n",
    "    'OHE_DIMENSION_30', 'OHE_DIMENSION_444', 'OHE_DIMENSION_19', 'OHE_DIMENSION_36', \n",
    "    'OHE_DIMENSION_17', 'OHE_DIMENSION_27', 'distance', 'OHE_DIMENSION_28', \n",
    "    'OHE_DIMENSION_37', 'OHE_DIMENSION_484', 'OHE_DIMENSION_16', 'crs_elapsed_time', \n",
    "    'OHE_DIMENSION_434', 'quarter', 'fl_number', 'OHE_DIMENSION_54', 'OHE_DIMENSION_35', \n",
    "    'OHE_DIMENSION_24', 'OHE_DIMENSION_52', 'OHE_DIMENSION_57', 'day_of_week', \n",
    "    'OHE_DIMENSION_816', 'OHE_DIMENSION_38', 'is_holiday_period', 'OHE_DIMENSION_50', \n",
    "    'OHE_DIMENSION_46', 'OHE_DIMENSION_73'\n",
    "]\n",
    "\n",
    "# 2. PRE-DEPARTURE FEATURES (EXCLUDING 'dep_delay' at index 9)\n",
    "DEP_DELAY_FEATURE_NAME = 'dep_delay'\n",
    "PRE_DEP_FEATURES = [f for f in IN_FLIGHT_FEATURES if f != DEP_DELAY_FEATURE_NAME]\n",
    "\n",
    "# 3. MODEL REGISTRY MAPPING (Use specific model names for each stage)\n",
    "MODEL_MAP = {\n",
    "    \"Pre-Departure\": {\n",
    "        \"features\": PRE_DEP_FEATURES,\n",
    "        \"name\": \"flight_delay_predictor_pre_dep\" # Assumes you registered two models\n",
    "    },\n",
    "    \"In-Flight\": {\n",
    "        \"features\": IN_FLIGHT_FEATURES,\n",
    "        \"name\": \"flight_delay_predictor_in_flight\" # Assumes you registered two models\n",
    "    }\n",
    "}\n",
    "# ---------------------------------------------\n",
    "\n",
    "# --- 4. DATA FETCHING (Unchanged from original code) ---\n",
    "\n",
    "def fetch_live_flight_data(base_url, api_key, flight_code, departure_date):\n",
    "    \"\"\"Fetches specific flight data from Aviationstack API...\"\"\"\n",
    "    # ... (function body for fetch_live_flight_data remains the same) ...\n",
    "    # This function is correct.\n",
    "\n",
    "    # Parse flight code (e.g., \"DL1585\" -> \"DL\" + \"1585\")\n",
    "    match = re.match(r\"([A-Za-z]+)(\\d+)\", flight_code)\n",
    "    if not match:\n",
    "        print(\"‚ùå Could not parse flight code into airline code and flight number.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    airline = match.group(1)\n",
    "    number = match.group(2)\n",
    "\n",
    "    endpoint = \"/flights\"\n",
    "\n",
    "    # Valid free-tier attempts (ordered by likelihood of success on restricted tiers)\n",
    "    attempts = [\n",
    "        # 1. Separate components: airline_iata + flight_number (often the most reliable on lower tiers)\n",
    "        {\"airline_iata\": airline, \"flight_number\": number},\n",
    "        \n",
    "        # 2. Combined IATA code\n",
    "        {\"flight_iata\": flight_code},\n",
    "        \n",
    "        # 3. Combined ICAO code (the original failing query format, included as a final try)\n",
    "        {\"flight_icao\": flight_code},\n",
    "    ]\n",
    "    \n",
    "    flights_data = []\n",
    "\n",
    "    for attempt in attempts:\n",
    "        # Include required parameters: access_key, flight_date, limit=1\n",
    "        params = {\"access_key\": api_key, \"flight_date\": departure_date, \"limit\": 1, **attempt}\n",
    "        \n",
    "        print(f\"Trying query: {list(attempt.keys())[0]}...\")\n",
    "\n",
    "        try:\n",
    "            response = requests.get(f\"{base_url}{endpoint}\", params=params)\n",
    "            response.raise_for_status() \n",
    "            data = response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # Handle connectivity or HTTP status errors\n",
    "            print(f\"‚ùå API Request Failed with {e}\")\n",
    "            continue\n",
    "\n",
    "        # Detect Aviationstack application errors (e.g., 403 status might still return JSON with 'error')\n",
    "        if \"error\" in data:\n",
    "            print(f\"‚ùå API Error for attempt {list(attempt.keys())[0]}: {data['error']['message']}\")\n",
    "            continue\n",
    "\n",
    "        flights = data.get(\"data\", [])\n",
    "        if flights:\n",
    "            print(f\"‚úÖ SUCCESS: Data retrieved using {list(attempt.keys())[0]} filter.\")\n",
    "            flights_data = flights\n",
    "            break # Exit loop on first successful query\n",
    "\n",
    "    if not flights_data:\n",
    "        print(\"‚ùå No valid data found for any API query method.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- DATA EXTRACTION & FLATTENING (Original logic to preserve downstream schema) ---\n",
    "    extracted_flights = []\n",
    "    for flight in flights_data:\n",
    "        # ... (rest of the data extraction/flattening remains the same) ...\n",
    "        flight_info = flight.get('flight', {}) or {}\n",
    "        airline_info = flight.get('airline', {}) or {}\n",
    "        departure_info = flight.get('departure', {}) or {}\n",
    "        arrival_info = flight.get('arrival', {}) or {}\n",
    "        aircraft_info = flight.get('aircraft', {}) or {}\n",
    "        live_info = flight.get('live', {}) or {}\n",
    "\n",
    "        flight_record = {\n",
    "            'flight_date': flight.get('flight_date'),\n",
    "            'flight_status': flight.get('flight_status'),\n",
    "            \n",
    "            # Flight Info\n",
    "            'flight_iata': flight_info.get('iata'),\n",
    "            'flight_icao': flight_info.get('icao'),\n",
    "            'flight_number': flight_info.get('number'),\n",
    "            \n",
    "            # Airline Info\n",
    "            'airline_name': airline_info.get('name'),\n",
    "            'airline_iata': airline_info.get('iata'),\n",
    "            'airline_icao': airline_info.get('icao'),\n",
    "            \n",
    "            # Departure Info (Crucial for Pre-Departure Model)\n",
    "            'departure_airport': departure_info.get('airport'),\n",
    "            'departure_iata': departure_info.get('iata'),\n",
    "            'departure_icao': departure_info.get('icao'),\n",
    "            'departure_delay': departure_info.get('delay'), # The raw feature you need\n",
    "            'departure_scheduled': departure_info.get('scheduled'),\n",
    "            'departure_estimated': departure_info.get('estimated'),\n",
    "            'departure_actual': departure_info.get('actual'),\n",
    "            'departure_timezone': departure_info.get('timezone'),\n",
    "            \n",
    "            # Arrival Info\n",
    "            'arrival_airport': arrival_info.get('airport'),\n",
    "            'arrival_iata': arrival_info.get('iata'),\n",
    "            'arrival_icao': arrival_info.get('icao'),\n",
    "            'arrival_scheduled': arrival_info.get('scheduled'),\n",
    "            \n",
    "            # Live Data (Crucial for In-Flight Model)\n",
    "            'live_latitude': live_info.get('latitude'),\n",
    "            'live_longitude': live_info.get('longitude'),\n",
    "            'live_altitude': live_info.get('altitude'),\n",
    "            'live_speed_horizontal': live_info.get('speed_horizontal'),\n",
    "            'live_is_ground': live_info.get('is_ground')\n",
    "        }\n",
    "        extracted_flights.append(flight_record)\n",
    "        \n",
    "    df = pd.DataFrame(extracted_flights)\n",
    "    print(f\"Successfully extracted {len(df)} flight record(s).\")\n",
    "    return df\n",
    "\n",
    "# --- 5. CORE EXECUTION ---\n",
    "live_flight_df = fetch_live_flight_data(BASE_URL, API_KEY, CLEAN_FLIGHT_CODE, p_departure_date)\n",
    "\n",
    "if not live_flight_df.empty:\n",
    "    print(\"\\n--- Fetched Data Head ---\\n\")\n",
    "    print(live_flight_df.head().to_markdown(index=False))\n",
    "\n",
    "# --- 6. FEATURE ENGINEERING (Corrected for Data Flow) ---\n",
    "\n",
    "# WARNING: This simplified function is sufficient for the NON-OHE features, \n",
    "# but it CANNOT correctly generate the 819-dimension OHE features \n",
    "# without the learned vocabulary (StringIndexer) from your training pipeline.\n",
    "\n",
    "# *** CRITICAL ACTION ***\n",
    "# To make this production-ready, you must:\n",
    "# 1. Save the fitted Spark ML Pipeline (or at least the StringIndexer & OneHotEncoder stages) \n",
    "#    from the Gold table creation notebook to a known location (e.g., an MLflow artifact).\n",
    "# 2. Load those stages here and use them to transform the live flight data.\n",
    "\n",
    "def engineer_live_features_simplified(live_df, required_features, dep_delay_name):\n",
    "    \"\"\"\n",
    "    Transforms raw API DataFrame into a feature vector using a simplified mapping \n",
    "    for the selected NON-OHE features. OHE features are created as placeholders.\n",
    "    \"\"\"\n",
    "    if live_df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    flight = live_df.iloc[0].copy() \n",
    "    \n",
    "    # 1. TEMPORAL & NUMERICAL FEATURES MAPPING\n",
    "    features = {}\n",
    "    \n",
    "    # Map API fields to the 16 non-OHE features defined by your Gold table pipeline\n",
    "    scheduled_time_str = flight['departure_scheduled']\n",
    "    try:\n",
    "        scheduled_dt = datetime.fromisoformat(scheduled_time_str.replace('Z', '+00:00'))\n",
    "    except (ValueError, TypeError):\n",
    "        print(\"Warning: Could not parse scheduled departure time. Defaulting to now.\")\n",
    "        scheduled_dt = datetime.now() \n",
    "\n",
    "    # Numerical features derived from API\n",
    "    features['flight_month'] = scheduled_dt.month\n",
    "    features['flight_year'] = scheduled_dt.year\n",
    "    features['day_of_week'] = scheduled_dt.weekday() \n",
    "    features['week_of_year'] = scheduled_dt.isocalendar()[1]\n",
    "    features['day_of_month'] = scheduled_dt.day\n",
    "    features['quarter'] = (scheduled_dt.month - 1) // 3 + 1\n",
    "    \n",
    "    # This is a proxy for fl_number. Your real pipeline would need a mapping.\n",
    "    # Assuming 'flight_number' API field corresponds to 'fl_number' in your gold table.\n",
    "    features['fl_number'] = float(flight.get('flight_number')) if flight.get('flight_number') is not None else 0.0\n",
    "\n",
    "    # These features are typically computed/available in your Silver layer.\n",
    "    # We use reasonable approximations based on common flight data sources.\n",
    "    # CRITICAL: Missing crs_elapsed_time and distance in API; must be looked up in a static table. \n",
    "    # For now, setting to 0.0 to prevent a crash.\n",
    "    features['crs_elapsed_time'] = 0.0 # Must be looked up!\n",
    "    features['distance'] = 0.0 # Must be looked up!\n",
    "\n",
    "    # The key delay feature\n",
    "    raw_delay = flight.get('departure_delay')\n",
    "    features[dep_delay_name] = float(raw_delay) if raw_delay is not None else 0.0\n",
    "    \n",
    "    # Time features conversion (HHMM to hour) - must be done carefully\n",
    "    features['dep_hour'] = scheduled_dt.hour\n",
    "    \n",
    "    # Boolean features (assuming default values for API data)\n",
    "    # The API doesn't provide these, so we set them to their most common value (0) \n",
    "    # or require a lookup table for holidays.\n",
    "    features['is_weekend'] = 1 if scheduled_dt.weekday() >= 5 else 0\n",
    "    features['is_holiday'] = 0\n",
    "    features['is_near_holiday'] = 0\n",
    "    features['is_holiday_period'] = 0\n",
    "    \n",
    "    # 2. OHE FEATURES (Placeholder)\n",
    "    # This must be replaced with the actual OHE logic from your fitted pipeline.\n",
    "    # For the simulation to work, we create 0-filled columns for the selected OHE dimensions.\n",
    "    # The actual values would only be 1 in a single position if the category matches.\n",
    "    ohe_columns = [f for f in required_features if f.startswith('OHE_DIMENSION')]\n",
    "    for ohe_col in ohe_columns:\n",
    "        # Assuming the vast majority of OHE features are 0 (i.e., this flight doesn't match that category/dimension)\n",
    "        features[ohe_col] = 0.0 \n",
    "\n",
    "    # 3. Final Assembly\n",
    "    engineered_df = pd.DataFrame([features])\n",
    "\n",
    "    # 4. FINAL SELECTION & ORDERING\n",
    "    # This step is the most critical: it ensures the final vector matches the model's required input shape.\n",
    "    final_feature_vector = engineered_df.reindex(columns=required_features, fill_value=0)\n",
    "    \n",
    "    return final_feature_vector\n",
    "\n",
    "\n",
    "# --- 7. DYNAMIC EXECUTION ---\n",
    "# Get dynamic config based on widget input\n",
    "current_config = MODEL_MAP[p_current_stage]\n",
    "REQUIRED_FEATURES = current_config[\"features\"]\n",
    "MODEL_NAME = current_config[\"name\"]\n",
    "MODEL_STAGE = \"Staging\" # Or 'Production' if you promoted it\n",
    "\n",
    "print(f\"\\n--- Dynamic Configuration ---\")\n",
    "print(f\"Prediction Stage: {p_current_stage}\")\n",
    "print(f\"Model to Load: {MODEL_NAME}\")\n",
    "print(f\"Feature Vector Size: {len(REQUIRED_FEATURES)}\")\n",
    "print(f\"---------------------------\\n\")\n",
    "\n",
    "try:\n",
    "    # Use the corrected feature engineering function\n",
    "    live_features_df = engineer_live_features_simplified(\n",
    "        live_flight_df, \n",
    "        REQUIRED_FEATURES, \n",
    "        DEP_DELAY_FEATURE_NAME\n",
    "    )\n",
    "    print(f\"\\n--- Engineered Feature Vector Shape: {live_features_df.shape} ---\")\n",
    "    print(f\"Features used: {len(live_features_df.columns)}\")\n",
    "    print(f\"Features (First 5): {live_features_df.columns.tolist()[:5]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Feature Engineering Failed: {e}\")\n",
    "    live_features_df = pd.DataFrame() \n",
    "\n",
    "# --- 8. MODEL LOADING AND PREDICTION (Now Dynamic) ---\n",
    "\n",
    "if not live_features_df.empty:\n",
    "    print(f\"\\nLoading Model '{MODEL_NAME}' from stage '{MODEL_STAGE}'...\")\n",
    "    try:\n",
    "        import mlflow.pyfunc\n",
    "        \n",
    "        # Load the model dynamically based on the current stage's config\n",
    "        logged_model_uri = f\"models:/{MODEL_NAME}/{MODEL_STAGE}\"\n",
    "        predictor = mlflow.pyfunc.load_model(logged_model_uri)\n",
    "        \n",
    "        # Run prediction on the engineered feature vector\n",
    "        prediction_result = predictor.predict(live_features_df)\n",
    "        \n",
    "        predicted_delay_minutes = prediction_result[0]\n",
    "        \n",
    "        print(f\"\\n‚úÖ Prediction Successful!\")\n",
    "        print(f\"‚úàÔ∏è Predicted Delay: {predicted_delay_minutes:.1f} minutes\")\n",
    "        \n",
    "        # Display Final Prediction\n",
    "        html_output = f\"\"\"\n",
    "        <div style='padding: 20px; border: 2px solid #3b82f6; border-radius: 12px; background-color: #e0f2fe; text-align: center;'>\n",
    "            <h1 style='color: #1d4ed8; font-size: 1.5rem; margin-bottom: 5px;'>Flight Delay Prediction ({p_current_stage})</h1>\n",
    "            <p style='color: #0c4a6e; font-size: 2.5rem; font-weight: bold;'>{predicted_delay_minutes:.1f} minutes</p>\n",
    "            <p style='color: #0c4a6e; font-size: 1.0rem;'>Predicted delay for flight {p_flight_icao} on {p_departure_date}.</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        # NOTE: displayHTML is a Databricks utility, here it is used conceptually.\n",
    "        # displayHTML(html_output)\n",
    "        print(\"\\n--- HTML Dashboard Output Generated ---\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"MLflow Model Loading or Prediction Failed: {e}\")\n",
    "        error_html = f\"\"\"\n",
    "        <div style='padding: 20px; border: 2px solid #ef4444; border-radius: 12px; background-color: #fee2e2; text-align: center;'>\n",
    "            <h1 style='color: #b91c1c; font-size: 1.5rem; margin-bottom: 5px;'>Prediction Failed</h1>\n",
    "            <p style='color: #7f1d1d; font-size: 1.0rem;'>Failed to load or run model **{MODEL_NAME}**. Check model registry and feature alignment. Error: {str(e)}</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        # displayHTML(error_html)\n",
    "        print(\"\\n--- HTML ERROR: Prediction Failed ---\")\n",
    "else:\n",
    "    error_html = f\"\"\"\n",
    "    <div style='padding: 20px; border: 2px solid #fb923c; border-radius: 12px; background-color: #fff7ed; text-align: center;'>\n",
    "        <h1 style='color: #c2410c; font-size: 1.5rem; margin-bottom: 5px;'>Data Retrieval Failed</h1>\n",
    "        <p style='color: #7c2d12; font-size: 1.0rem;'>Could not fetch flight data from the API or feature engineering failed. Check API inputs and connection.</p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    # displayHTML(error_html)\n",
    "    print(\"\\n--- HTML ERROR: Data Retrieval Failed ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c89f82b-8527-4f68-a04f-475f8b1e9f11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, when, udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Initialize Spark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "print(\"‚úÖ Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7ef651e-4115-41ca-a3ea-13f9310db843",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 2: Configuration Class\n",
    "class APIConfig:\n",
    "    \"\"\"Configuration for Aviation Stack API and MLflow\"\"\"\n",
    "    \n",
    "    # API Configuration\n",
    "    API_KEY = dbutils.secrets.get(scope=\"my-secrets\", key=\"aviation_stack_api\")\n",
    "    BASE_URL = \"https://api.aviationstack.com/v1\"\n",
    "    \n",
    "    # MLflow Configuration\n",
    "    MLFLOW_TRACKING_URI = \"databricks\"\n",
    "    MLFLOW_REGISTRY_URI = \"databricks\"\n",
    "    EXPERIMENT_NAME = \"/Shared/Flightmasters_Optimized_Experiments\"\n",
    "    \n",
    "    # Model Names (from your experiments)\n",
    "    MODEL_RF_PRE = \"model_rf_pre\"\n",
    "    MODEL_GBT_PRE = \"model_gbt_pre\"\n",
    "    MODEL_RF_IN = \"model_rf_in\"\n",
    "    MODEL_GBT_IN = \"model_gbt_in\"\n",
    "    \n",
    "    # Feature Engineering\n",
    "    SELECTED_INDICES = [9, 10, 11, 47, 23, 817, 42, 43, 451, 3, 0, 814, 1, 30, 444, \n",
    "                        19, 36, 17, 27, 8, 28, 37, 484, 16, 7, 434, 5, 6, 54, 35, \n",
    "                        24, 52, 57, 2, 816, 38, 15, 50, 46, 73]\n",
    "    \n",
    "    DEP_DELAY_ORIGINAL_INDEX = 11  # Position in numerical features\n",
    "    TOP_K_FEATURES = 40\n",
    "    \n",
    "    # Delta Table Paths\n",
    "    PREDICTIONS_TABLE = \"default.flight_predictions\"\n",
    "    PREDICTIONS_PATH = \"/Volumes/workspace/default/ds-capstone/predictions/api_predictions\"\n",
    "    \n",
    "    # Gold Table (for feature engineering reference)\n",
    "    GOLD_TABLE = \"default.gold_ml_features_experimental\"\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "479d8a4f-01c4-474f-a2c5-37e3ec55a863",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 3: Aviation Stack API Client\n",
    "class AviationStackClient:\n",
    "    \"\"\"Client for Aviation Stack API calls\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, base_url: str):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "    \n",
    "    def search_flight(self, flight_iata: str = None, flight_date: str = None, \n",
    "                      dep_iata: str = None, arr_iata: str = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Search for flight information\n",
    "        \n",
    "        Args:\n",
    "            flight_iata: Flight number (e.g., 'AA100')\n",
    "            flight_date: Date in YYYY-MM-DD format\n",
    "            dep_iata: Departure airport code (e.g., 'JFK')\n",
    "            arr_iata: Arrival airport code (e.g., 'LAX')\n",
    "        \"\"\"\n",
    "        endpoint = f\"{self.base_url}/flights\"\n",
    "        \n",
    "        params = {\n",
    "            'access_key': self.api_key,\n",
    "            'limit': 100\n",
    "        }\n",
    "        \n",
    "        # Add search parameters\n",
    "        if flight_iata:\n",
    "            params['flight_iata'] = flight_iata\n",
    "        if flight_date:\n",
    "            params['flight_date'] = flight_date\n",
    "        if dep_iata:\n",
    "            params['dep_iata'] = dep_iata\n",
    "        if arr_iata:\n",
    "            params['arr_iata'] = arr_iata\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(endpoint, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            print(f\"‚úÖ API call successful: {len(data.get('data', []))} flights found\")\n",
    "            return data\n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"‚ùå API Error: {e}\")\n",
    "            return {'data': [], 'error': str(e)}\n",
    "    \n",
    "    def get_flight_by_number(self, flight_number: str, date: str = None) -> Optional[Dict]:\n",
    "        \"\"\"Get specific flight by flight number\"\"\"\n",
    "        if date is None:\n",
    "            date = datetime.now().strftime('%Y-%m-%d')\n",
    "        \n",
    "        result = self.search_flight(flight_iata=flight_number, flight_date=date)\n",
    "        flights = result.get('data', [])\n",
    "        \n",
    "        if flights:\n",
    "            return flights[0]\n",
    "        return None\n",
    "    \n",
    "    def get_route_flights(self, dep_iata: str, arr_iata: str, date: str = None) -> List[Dict]:\n",
    "        \"\"\"Get all flights for a specific route\"\"\"\n",
    "        if date is None:\n",
    "            date = datetime.now().strftime('%Y-%m-%d')\n",
    "        \n",
    "        result = self.search_flight(dep_iata=dep_iata, arr_iata=arr_iata, flight_date=date)\n",
    "        return result.get('data', [])\n",
    "\n",
    "print(\"‚úÖ Aviation Stack Client defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1f7e469-21b1-45ed-b933-a5adddcb4632",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 4: Feature Engineering for API Data\n",
    "class FlightFeatureEngineer:\n",
    "    \"\"\"\n",
    "    Feature engineering to match Gold table structure (819 features)\n",
    "    Must align with your Gold table feature engineering pipeline\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Load Gold table schema for reference\n",
    "        try:\n",
    "            self.gold_sample = spark.table(APIConfig.GOLD_TABLE).limit(1)\n",
    "            self.total_features = self.gold_sample.select(\"features\").first().features.size\n",
    "            print(f\"‚úÖ Gold table features: {self.total_features}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not load Gold table: {e}\")\n",
    "            self.total_features = 819\n",
    "    \n",
    "    def parse_api_flight(self, flight_data: Dict) -> Dict:\n",
    "        \"\"\"Extract relevant fields from API response\"\"\"\n",
    "        \n",
    "        flight_info = flight_data.get('flight', {}) or {}\n",
    "        airline_info = flight_data.get('airline', {}) or {}\n",
    "        departure_info = flight_data.get('departure', {}) or {}\n",
    "        arrival_info = flight_data.get('arrival', {}) or {}\n",
    "        \n",
    "        # Parse scheduled times\n",
    "        dep_scheduled = departure_info.get('scheduled', '')\n",
    "        arr_scheduled = arrival_info.get('scheduled', '')\n",
    "        \n",
    "        try:\n",
    "            dep_dt = pd.to_datetime(dep_scheduled) if dep_scheduled else None\n",
    "            arr_dt = pd.to_datetime(arr_scheduled) if arr_scheduled else None\n",
    "        except:\n",
    "            dep_dt = None\n",
    "            arr_dt = None\n",
    "        \n",
    "        # Extract time features\n",
    "        if dep_dt:\n",
    "            flight_month = dep_dt.month\n",
    "            flight_year = dep_dt.year\n",
    "            day_of_week = dep_dt.dayofweek\n",
    "            week_of_year = dep_dt.isocalendar()[1]\n",
    "            day_of_month = dep_dt.day\n",
    "            quarter = (dep_dt.month - 1) // 3 + 1\n",
    "            dep_hour = dep_dt.hour\n",
    "            is_weekend = 1 if dep_dt.dayofweek >= 5 else 0\n",
    "        else:\n",
    "            flight_month = flight_year = day_of_week = week_of_year = 0\n",
    "            day_of_month = quarter = dep_hour = is_weekend = 0\n",
    "        \n",
    "        if arr_dt:\n",
    "            arr_hour = arr_dt.hour\n",
    "        else:\n",
    "            arr_hour = 0\n",
    "        \n",
    "        # Calculate season\n",
    "        season = self._get_season(flight_month)\n",
    "        \n",
    "        # Get delay information\n",
    "        dep_delay = departure_info.get('delay', 0) or 0\n",
    "        arr_delay = arrival_info.get('delay')\n",
    "        \n",
    "        # Calculate elapsed time\n",
    "        if dep_dt and arr_dt:\n",
    "            crs_elapsed_time = (arr_dt - dep_dt).total_seconds() / 60  # minutes\n",
    "        else:\n",
    "            crs_elapsed_time = 0\n",
    "        \n",
    "        # Holiday detection (simplified - you may want to enhance this)\n",
    "        is_holiday, is_near_holiday, is_holiday_period = self._detect_holidays(dep_dt)\n",
    "        \n",
    "        return {\n",
    "            # Identifiers\n",
    "            'flight_number': flight_info.get('number', ''),\n",
    "            'flight_iata': flight_info.get('iata', ''),\n",
    "            'airline_name': airline_info.get('name', ''),\n",
    "            'airline_code': airline_info.get('iata', ''),\n",
    "            'origin_airport_code': departure_info.get('iata', ''),\n",
    "            'destination_airport_code': arrival_info.get('iata', ''),\n",
    "            \n",
    "            # Temporal features\n",
    "            'flight_month': flight_month,\n",
    "            'flight_year': flight_year,\n",
    "            'day_of_week': day_of_week,\n",
    "            'week_of_year': week_of_year,\n",
    "            'day_of_month': day_of_month,\n",
    "            'quarter': quarter,\n",
    "            'season': season,\n",
    "            'dep_hour': dep_hour,\n",
    "            'arr_hour': arr_hour,\n",
    "            \n",
    "            # Boolean features\n",
    "            'is_weekend': is_weekend,\n",
    "            'is_holiday': is_holiday,\n",
    "            'is_near_holiday': is_near_holiday,\n",
    "            'is_holiday_period': is_holiday_period,\n",
    "            \n",
    "            # Numerical features\n",
    "            'fl_number': int(flight_info.get('number', 0) or 0),\n",
    "            'crs_elapsed_time': crs_elapsed_time,\n",
    "            'distance': 0,  # Would need additional API or database lookup\n",
    "            'dep_delay': float(dep_delay),\n",
    "            'arr_delay': float(arr_delay) if arr_delay else None,\n",
    "            \n",
    "            # Metadata\n",
    "            'flight_date': flight_data.get('flight_date', ''),\n",
    "            'flight_status': flight_data.get('flight_status', ''),\n",
    "            'scheduled_departure': dep_scheduled,\n",
    "            'scheduled_arrival': arr_scheduled\n",
    "        }\n",
    "    \n",
    "    def _get_season(self, month: int) -> str:\n",
    "        \"\"\"Map month to season\"\"\"\n",
    "        if month in [12, 1, 2]:\n",
    "            return 'Winter'\n",
    "        elif month in [3, 4, 5]:\n",
    "            return 'Spring'\n",
    "        elif month in [6, 7, 8]:\n",
    "            return 'Summer'\n",
    "        else:\n",
    "            return 'Fall'\n",
    "    \n",
    "    def _detect_holidays(self, dt: Optional[pd.Timestamp]) -> Tuple[int, int, int]:\n",
    "        \"\"\"\n",
    "        Simplified holiday detection\n",
    "        Returns: (is_holiday, is_near_holiday, is_holiday_period)\n",
    "        \"\"\"\n",
    "        if dt is None:\n",
    "            return (0, 0, 0)\n",
    "        \n",
    "        # Major US holidays (simplified)\n",
    "        holidays = [\n",
    "            (1, 1),   # New Year's Day\n",
    "            (7, 4),   # Independence Day\n",
    "            (11, 11), # Veterans Day\n",
    "            (12, 25), # Christmas\n",
    "        ]\n",
    "        \n",
    "        month_day = (dt.month, dt.day)\n",
    "        is_holiday = 1 if month_day in holidays else 0\n",
    "        \n",
    "        # Near holiday (within 3 days)\n",
    "        is_near_holiday = 0\n",
    "        for h_month, h_day in holidays:\n",
    "            holiday_dt = pd.Timestamp(year=dt.year, month=h_month, day=h_day)\n",
    "            days_diff = abs((dt - holiday_dt).days)\n",
    "            if 0 < days_diff <= 3:\n",
    "                is_near_holiday = 1\n",
    "                break\n",
    "        \n",
    "        # Holiday period (Nov-Dec)\n",
    "        is_holiday_period = 1 if dt.month in [11, 12] else 0\n",
    "        \n",
    "        return (is_holiday, is_near_holiday, is_holiday_period)\n",
    "    \n",
    "    def create_feature_vector(self, parsed_flight: Dict) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Create feature vector matching Gold table structure (819 features)\n",
    "        This is a simplified version - ideally you'd use the same pipeline\n",
    "        \"\"\"\n",
    "        \n",
    "        # Numerical features (in order from Gold table)\n",
    "        numerical = [\n",
    "            parsed_flight['flight_month'],\n",
    "            parsed_flight['flight_year'],\n",
    "            parsed_flight['day_of_week'],\n",
    "            parsed_flight['week_of_year'],\n",
    "            parsed_flight['day_of_month'],\n",
    "            parsed_flight['quarter'],\n",
    "            parsed_flight['fl_number'],\n",
    "            parsed_flight['dep_hour'],\n",
    "            parsed_flight['arr_hour'],\n",
    "            parsed_flight['crs_elapsed_time'],\n",
    "            parsed_flight['distance'],\n",
    "            parsed_flight['dep_delay']\n",
    "        ]\n",
    "        \n",
    "        # Boolean features\n",
    "        boolean = [\n",
    "            parsed_flight['is_weekend'],\n",
    "            parsed_flight['is_holiday'],\n",
    "            parsed_flight['is_near_holiday'],\n",
    "            parsed_flight['is_holiday_period']\n",
    "        ]\n",
    "        \n",
    "        # Combine numerical and boolean\n",
    "        base_features = numerical + boolean  # 16 features\n",
    "        \n",
    "        # Categorical features would be one-hot encoded\n",
    "        # For simplicity, we'll create a placeholder vector\n",
    "        # In production, you'd need to use the same StringIndexer and OneHotEncoder\n",
    "        # fitted on your Gold table\n",
    "        \n",
    "        # Total features = 16 (base) + ~803 (one-hot encoded categoricals) = 819\n",
    "        categorical_placeholder = [0.0] * (self.total_features - len(base_features))\n",
    "        \n",
    "        full_vector = base_features + categorical_placeholder\n",
    "        \n",
    "        return np.array(full_vector, dtype=float)\n",
    "\n",
    "print(\"‚úÖ Feature Engineer defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7962c054-aa16-4541-930d-795136194ed5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 5: Model Loader\n",
    "class ModelLoader:\n",
    "    \"\"\"Load trained models from MLflow\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        mlflow.set_tracking_uri(APIConfig.MLFLOW_TRACKING_URI)\n",
    "        mlflow.set_registry_uri(APIConfig.MLFLOW_REGISTRY_URI)\n",
    "        \n",
    "        self.models = {}\n",
    "        self.model_info = {}\n",
    "    \n",
    "    def load_best_models(self, experiment_name: str):\n",
    "        \"\"\"Load the best performing models from the experiment\"\"\"\n",
    "        \n",
    "        print(f\"\\nüîç Searching for models in: {experiment_name}\")\n",
    "        \n",
    "        try:\n",
    "            experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "            if not experiment:\n",
    "                print(f\"‚ùå Experiment not found: {experiment_name}\")\n",
    "                return False\n",
    "            \n",
    "            # Get all runs from the experiment\n",
    "            runs = mlflow.search_runs(\n",
    "                experiment_ids=[experiment.experiment_id],\n",
    "                filter_string=\"\",\n",
    "                order_by=[\"metrics.auc_roc DESC\"]\n",
    "            )\n",
    "            \n",
    "            if runs.empty:\n",
    "                print(\"‚ùå No runs found in experiment\")\n",
    "                return False\n",
    "            \n",
    "            print(f\"‚úÖ Found {len(runs)} runs\")\n",
    "            \n",
    "            # Load each model type\n",
    "            model_types = {\n",
    "                'RF_Pre': 'RF_Pre_Departure',\n",
    "                'GBT_Pre': 'GBT_Pre_Departure',\n",
    "                'RF_In': 'RF_In_Flight',\n",
    "                'GBT_In': 'GBT_In_Flight'\n",
    "            }\n",
    "            \n",
    "            for model_key, run_name_pattern in model_types.items():\n",
    "                matching_runs = runs[runs['tags.mlflow.runName'].str.contains(run_name_pattern, na=False)]\n",
    "                \n",
    "                if not matching_runs.empty:\n",
    "                    best_run = matching_runs.iloc[0]\n",
    "                    run_id = best_run['run_id']\n",
    "                    auc_roc = best_run['metrics.auc_roc']\n",
    "                    \n",
    "                    # Load model\n",
    "                    try:\n",
    "                        model_uri = f\"runs:/{run_id}/model_{model_key.lower()}\"\n",
    "                        model = mlflow.spark.load_model(model_uri)\n",
    "                        \n",
    "                        self.models[model_key] = model\n",
    "                        self.model_info[model_key] = {\n",
    "                            'run_id': run_id,\n",
    "                            'auc_roc': auc_roc,\n",
    "                            'run_name': best_run['tags.mlflow.runName']\n",
    "                        }\n",
    "                        \n",
    "                        print(f\"‚úÖ Loaded {model_key}: AUC-ROC = {auc_roc:.4f}\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå Error loading {model_key}: {e}\")\n",
    "            \n",
    "            return len(self.models) > 0\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading models: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_model(self, model_type: str):\n",
    "        \"\"\"Get a specific model\"\"\"\n",
    "        return self.models.get(model_type)\n",
    "    \n",
    "    def get_model_info(self, model_type: str) -> Dict:\n",
    "        \"\"\"Get model metadata\"\"\"\n",
    "        return self.model_info.get(model_type, {})\n",
    "\n",
    "print(\"‚úÖ Model Loader defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8702ed8-dc74-476c-80be-d8421edc957c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 6: Prediction Engine\n",
    "class FlightDelayPredictor:\n",
    "    \"\"\"Make predictions using trained models\"\"\"\n",
    "    \n",
    "    def __init__(self, model_loader: ModelLoader, feature_engineer: FlightFeatureEngineer):\n",
    "        self.model_loader = model_loader\n",
    "        self.feature_engineer = feature_engineer\n",
    "        self.selected_indices = APIConfig.SELECTED_INDICES\n",
    "        self.dep_delay_index = APIConfig.DEP_DELAY_ORIGINAL_INDEX\n",
    "    \n",
    "    def _select_features(self, feature_vector: np.ndarray, remove_dep_delay: bool = False) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Select top-K features based on feature selection from experiments\n",
    "        Optionally remove dep_delay for pre-departure predictions\n",
    "        \"\"\"\n",
    "        # Select features by indices\n",
    "        selected = feature_vector[self.selected_indices]\n",
    "        \n",
    "        if remove_dep_delay:\n",
    "            # Find dep_delay in selected features and remove it\n",
    "            if self.dep_delay_index in self.selected_indices:\n",
    "                dep_delay_new_index = self.selected_indices.index(self.dep_delay_index)\n",
    "                selected = np.delete(selected, dep_delay_new_index)\n",
    "        \n",
    "        return selected\n",
    "    \n",
    "    def predict_single_flight(self, parsed_flight: Dict, use_dep_delay: bool = False) -> Dict:\n",
    "        \"\"\"\n",
    "        Make prediction for a single flight\n",
    "        \n",
    "        Args:\n",
    "            parsed_flight: Parsed flight data from API\n",
    "            use_dep_delay: If True, use in-flight models (with dep_delay)\n",
    "                          If False, use pre-departure models (without dep_delay)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create full feature vector\n",
    "        full_vector = self.feature_engineer.create_feature_vector(parsed_flight)\n",
    "        \n",
    "        # Select top-K features\n",
    "        if use_dep_delay:\n",
    "            # In-flight prediction (use dep_delay)\n",
    "            features = self._select_features(full_vector, remove_dep_delay=False)\n",
    "            model_rf = self.model_loader.get_model('RF_In')\n",
    "            model_gbt = self.model_loader.get_model('GBT_In')\n",
    "            prediction_type = 'in_flight'\n",
    "        else:\n",
    "            # Pre-departure prediction (remove dep_delay)\n",
    "            features = self._select_features(full_vector, remove_dep_delay=True)\n",
    "            model_rf = self.model_loader.get_model('RF_Pre')\n",
    "            model_gbt = self.model_loader.get_model('GBT_Pre')\n",
    "            prediction_type = 'pre_departure'\n",
    "        \n",
    "        if model_rf is None or model_gbt is None:\n",
    "            return {\n",
    "                'error': f'Models not loaded for {prediction_type}',\n",
    "                'prediction_type': prediction_type\n",
    "            }\n",
    "        \n",
    "        # Create Spark DataFrame with feature vector\n",
    "        features_vector = Vectors.dense(features.tolist())\n",
    "        \n",
    "        df = spark.createDataFrame(\n",
    "            [(features_vector,)],\n",
    "            schema=StructType([\n",
    "                StructField(\"features\", VectorUDT(), nullable=False)\n",
    "            ])\n",
    "        )\n",
    "        \n",
    "        # Make predictions\n",
    "        try:\n",
    "            pred_rf = model_rf.transform(df).select(\"prediction\", \"probability\").first()\n",
    "            pred_gbt = model_gbt.transform(df).select(\"prediction\", \"probability\").first()\n",
    "            \n",
    "            # Extract probabilities\n",
    "            prob_rf = float(pred_rf['probability'][1])  # Probability of delay\n",
    "            prob_gbt = float(pred_gbt['probability'][1])\n",
    "            \n",
    "            # Ensemble prediction (average)\n",
    "            ensemble_prob = (prob_rf + prob_gbt) / 2\n",
    "            ensemble_prediction = 1 if ensemble_prob >= 0.5 else 0\n",
    "            \n",
    "            return {\n",
    "                'flight_iata': parsed_flight['flight_iata'],\n",
    "                'airline_name': parsed_flight['airline_name'],\n",
    "                'origin': parsed_flight['origin_airport_code'],\n",
    "                'destination': parsed_flight['destination_airport_code'],\n",
    "                'scheduled_departure': parsed_flight['scheduled_departure'],\n",
    "                'prediction_type': prediction_type,\n",
    "                'rf_prediction': int(pred_rf['prediction']),\n",
    "                'rf_delay_probability': prob_rf,\n",
    "                'gbt_prediction': int(pred_gbt['prediction']),\n",
    "                'gbt_delay_probability': prob_gbt,\n",
    "                'ensemble_prediction': ensemble_prediction,\n",
    "                'ensemble_delay_probability': ensemble_prob,\n",
    "                'actual_dep_delay': parsed_flight.get('dep_delay'),\n",
    "                'actual_arr_delay': parsed_flight.get('arr_delay'),\n",
    "                'flight_status': parsed_flight['flight_status'],\n",
    "                'prediction_timestamp': datetime.now().isoformat(),\n",
    "                'model_rf_info': self.model_loader.get_model_info('RF_In' if use_dep_delay else 'RF_Pre'),\n",
    "                'model_gbt_info': self.model_loader.get_model_info('GBT_In' if use_dep_delay else 'GBT_Pre')\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'error': f'Prediction failed: {str(e)}',\n",
    "                'flight_iata': parsed_flight['flight_iata'],\n",
    "                'prediction_type': prediction_type\n",
    "            }\n",
    "    \n",
    "    def predict_multiple_flights(self, api_flights: List[Dict], use_dep_delay: bool = False) -> List[Dict]:\n",
    "        \"\"\"Make predictions for multiple flights\"\"\"\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        for flight_data in api_flights:\n",
    "            parsed = self.feature_engineer.parse_api_flight(flight_data)\n",
    "            prediction = self.predict_single_flight(parsed, use_dep_delay)\n",
    "            predictions.append(prediction)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "print(\"‚úÖ Prediction Engine defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e975c132-1c2f-49f1-9731-5c232ad12177",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 7: Results Storage\n",
    "class PredictionStorage:\n",
    "    \"\"\"Store predictions to Delta Lake for dashboard consumption\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.table_name = APIConfig.PREDICTIONS_TABLE\n",
    "        self.table_path = APIConfig.PREDICTIONS_PATH\n",
    "    \n",
    "    def save_predictions(self, predictions: List[Dict]) -> bool:\n",
    "        \"\"\"Save predictions to Delta table\"\"\"\n",
    "        \n",
    "        if not predictions:\n",
    "            print(\"‚ö†Ô∏è No predictions to save\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # Convert to DataFrame\n",
    "            df = pd.DataFrame(predictions)\n",
    "            \n",
    "            # Convert to Spark DataFrame\n",
    "            spark_df = spark.createDataFrame(df)\n",
    "            \n",
    "            # Add metadata\n",
    "            spark_df = spark_df.withColumn(\"ingestion_timestamp\", lit(datetime.now()))\n",
    "            \n",
    "            print(f\"\\nüíæ Saving {len(predictions)} predictions...\")\n",
    "            \n",
    "            # Create directory if needed\n",
    "            try:\n",
    "                dbutils.fs.mkdirs(self.table_path.rsplit('/', 1)[0])\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Write to Delta (append mode for dashboard)\n",
    "            spark_df.write.format(\"delta\").mode(\"append\").save(self.table_path)\n",
    "            \n",
    "            # Register table if not exists\n",
    "            try:\n",
    "                spark.sql(f\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS {self.table_name}\n",
    "                    USING DELTA\n",
    "                    LOCATION '{self.table_path}'\n",
    "                \"\"\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Table registration warning: {e}\")\n",
    "            \n",
    "            print(f\"‚úÖ Predictions saved to {self.table_name}\")\n",
    "            return True\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving predictions: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_recent_predictions(self, limit: int = 100):\n",
    "        \"\"\"Retrieve recent predictions for verification\"\"\"\n",
    "        try:\n",
    "            df = spark.table(self.table_name).orderBy(col(\"prediction_timestamp\").desc()).limit(limit)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error reading predictions: {e}\")\n",
    "            return None\n",
    "\n",
    "print(\"‚úÖ Prediction Storage defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84fa86f3-9dc0-4b59-848a-014fef63ce2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 8: Main Prediction Pipeline\n",
    "class FlightDelayPipeline:\n",
    "    \"\"\"Main orchestration class\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"FLIGHT DELAY PREDICTION PIPELINE\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Initialize components\n",
    "        self.api_client = AviationStackClient(APIConfig.API_KEY, APIConfig.BASE_URL)\n",
    "        self.feature_engineer = FlightFeatureEngineer()\n",
    "        self.model_loader = ModelLoader()\n",
    "        self.storage = PredictionStorage()\n",
    "        \n",
    "        # Load models\n",
    "        print(\"\\nüì¶ Loading trained models...\")\n",
    "        success = self.model_loader.load_best_models(APIConfig.EXPERIMENT_NAME)\n",
    "        \n",
    "        if not success:\n",
    "            print(\"‚ùå Failed to load models\")\n",
    "            return\n",
    "        \n",
    "        # Initialize predictor\n",
    "        self.predictor = FlightDelayPredictor(self.model_loader, self.feature_engineer)\n",
    "        \n",
    "        print(\"\\n‚úÖ Pipeline initialized successfully\")\n",
    "    \n",
    "    def predict_flight_by_number(self, flight_number: str, date: str = None, \n",
    "                                  use_dep_delay: bool = False) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Predict delay for a specific flight number\n",
    "        \n",
    "        Args:\n",
    "            flight_number: Flight number (e.g., 'AA100')\n",
    "            date: Date in YYYY-MM-DD format (default: today)\n",
    "            use_dep_delay: Use in-flight model (True) or pre-departure model (False)\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"\\nüîç Searching for flight: {flight_number}\")\n",
    "        \n",
    "        # Get flight from API\n",
    "        flight_data = self.api_client.get_flight_by_number(flight_number, date)\n",
    "        \n",
    "        if not flight_data:\n",
    "            print(f\"‚ùå Flight {flight_number} not found\")\n",
    "            return None\n",
    "        \n",
    "        # Parse and predict\n",
    "        parsed = self.feature_engineer.parse_api_flight(flight_data)\n",
    "        prediction = self.predictor.predict_single_flight(parsed, use_dep_delay)\n",
    "        \n",
    "        # Save to Delta\n",
    "        self.storage.save_predictions([prediction])\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    def predict_route(self, dep_iata: str, arr_iata: str, date: str = None,\n",
    "                     use_dep_delay: bool = False) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Predict delays for all flights on a route\n",
    "        \n",
    "        Args:\n",
    "            dep_iata: Departure airport code\n",
    "            arr_iata: Arrival airport code\n",
    "            date: Date in YYYY-MM-DD format (default: today)\n",
    "            use_dep_delay: Use in-flight model (True) or pre-departure model (False)\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"\\nüîç Searching for flights: {dep_iata} ‚Üí {arr_iata}\")\n",
    "        \n",
    "        # Get flights from API\n",
    "        flights = self.api_client.get_route_flights(dep_iata, arr_iata, date)\n",
    "        \n",
    "        if not flights:\n",
    "            print(f\"‚ùå No flights found for route {dep_iata} ‚Üí {arr_iata}\")\n",
    "            return []\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = self.predictor.predict_multiple_flights(flights, use_dep_delay)\n",
    "        \n",
    "        # Save to Delta\n",
    "        self.storage.save_predictions(predictions)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def display_prediction(self, prediction: Dict):\n",
    "        \"\"\"Pretty print a prediction result\"\"\"\n",
    "        \n",
    "        if 'error' in prediction:\n",
    "            print(f\"\\n‚ùå {prediction['error']}\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"PREDICTION RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\n‚úàÔ∏è Flight Information:\")\n",
    "        print(f\"   Flight: {prediction['flight_iata']}\")\n",
    "        print(f\"   Airline: {prediction['airline_name']}\")\n",
    "        print(f\"   Route: {prediction['origin']} ‚Üí {prediction['destination']}\")\n",
    "        print(f\"   Scheduled: {prediction['scheduled_departure']}\")\n",
    "        print(f\"   Status: {prediction['flight_status']}\")\n",
    "        \n",
    "        print(f\"\\nü§ñ Prediction Type: {prediction['prediction_type'].upper()}\")\n",
    "        \n",
    "        print(f\"\\nüìä Model Predictions:\")\n",
    "        print(f\"   Random Forest:\")\n",
    "        print(f\"      Delay Prediction: {'DELAYED' if prediction['rf_prediction'] == 1 else 'ON-TIME'}\")\n",
    "        print(f\"      Delay Probability: {prediction['rf_delay_probability']*100:.1f}%\")\n",
    "        \n",
    "        print(f\"\\n   Gradient Boosted Trees:\")\n",
    "        print(f\"      Delay Prediction: {'DELAYED' if prediction['gbt_prediction'] == 1 else 'ON-TIME'}\")\n",
    "        print(f\"      Delay Probability: {prediction['gbt_delay_probability']*100:.1f}%\")\n",
    "        \n",
    "        print(f\"\\n   üéØ ENSEMBLE (Recommended):\")\n",
    "        print(f\"      Delay Prediction: {'DELAYED' if prediction['ensemble_prediction'] == 1 else 'ON-TIME'}\")\n",
    "        print(f\"      Delay Probability: {prediction['ensemble_delay_probability']*100:.1f}%\")\n",
    "        \n",
    "        if prediction.get('actual_dep_delay') is not None:\n",
    "            print(f\"\\nüìç Actual Departure Delay: {prediction['actual_dep_delay']:.0f} minutes\")\n",
    "        \n",
    "        confidence = \"HIGH\" if abs(prediction['ensemble_delay_probability'] - 0.5) > 0.3 else \"MEDIUM\" if abs(prediction['ensemble_delay_probability'] - 0.5) > 0.15 else \"LOW\"\n",
    "        print(f\"\\nüéöÔ∏è Confidence Level: {confidence}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "print(\"‚úÖ Pipeline class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97409b6b-fc37-43c3-bb4f-a360bb29de5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 9: Initialize Pipeline\n",
    "# Create pipeline instance\n",
    "pipeline = FlightDelayPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebdcf812-bb63-4a79-85b0-89d004221bff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 10: Example 1 - Predict Single Flight (Pre-Departure)\n",
    "# Example: Predict a specific flight before departure\n",
    "\n",
    "flight_number = \"AA100\"  # Replace with actual flight number\n",
    "date = \"2025-11-30\"  # Replace with desired date\n",
    "\n",
    "prediction = pipeline.predict_flight_by_number(\n",
    "    flight_number=flight_number,\n",
    "    date=date,\n",
    "    use_dep_delay=False  # Pre-departure prediction\n",
    ")\n",
    "\n",
    "if prediction:\n",
    "    pipeline.display_prediction(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cdc256f-77df-4611-b480-df404da3f57b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 11: Example 2 - Predict Single Flight (In-Flight)\n",
    "# Example: Predict with departure delay information (in-flight)\n",
    "\n",
    "flight_number = \"AA100\"\n",
    "date = \"2025-11-30\"\n",
    "\n",
    "prediction = pipeline.predict_flight_by_number(\n",
    "    flight_number=flight_number,\n",
    "    date=date,\n",
    "    use_dep_delay=True \n",
    ")\n",
    "\n",
    "if prediction:\n",
    "    pipeline.display_prediction(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "193ce450-b028-40e4-a1d4-d459d4a69bd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Flightmasters_Delay_Prediction",
   "widgets": {
    "p_current_stage": {
     "currentValue": "Pre-Departure",
     "nuid": "eb362037-e939-4b6d-948c-9aec9f8f4152",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "Pre-Departure",
      "label": "Current Prediction Stage",
      "name": "p_current_stage",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "Pre-Departure",
        "In-Flight"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "Pre-Departure",
      "label": "Current Prediction Stage",
      "name": "p_current_stage",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "Pre-Departure",
        "In-Flight"
       ]
      }
     }
    },
    "p_departure_date": {
     "currentValue": "2025-11-29",
     "nuid": "e20912a4-c94a-4f35-9717-535e2a1b49a3",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-11-30",
      "label": "Departure Date (YYYY-MM-DD)",
      "name": "p_departure_date",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-11-30",
      "label": "Departure Date (YYYY-MM-DD)",
      "name": "p_departure_date",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "p_flight_icao": {
     "currentValue": "DL1284",
     "nuid": "71bfe7b1-ec01-411d-a3e8-060e82fd752c",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "DAL1234",
      "label": "Flight ICAO Code",
      "name": "p_flight_icao",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "DAL1234",
      "label": "Flight ICAO Code",
      "name": "p_flight_icao",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
