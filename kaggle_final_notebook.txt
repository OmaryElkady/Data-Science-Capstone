# FLIGHT DELAY PREDICTION - FINAL KAGGLE NOTEBOOK
# Upload flights_processed.csv to Kaggle and copy-paste this code

# =============================================================================
# CELL 1: Install Packages
# =============================================================================

%pip install -q torch tensorflow xgboost lightgbm
print("‚úÖ All packages installed successfully!")

# =============================================================================
# CELL 2: Import Libraries
# =============================================================================

import pandas as pd
import numpy as np
import joblib
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import (
    classification_report, confusion_matrix, accuracy_score,
    precision_score, recall_score, f1_score, roc_auc_score, roc_curve
)
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')

# GPU/TPU detection and setup
import os
import torch
import tensorflow as tf

# Set style for better plots
plt.style.use('default')
sns.set_palette("husl")

print("‚úÖ Libraries imported successfully!")

# =============================================================================
# CELL 3: GPU/TPU Detection
# =============================================================================

def setup_gpu_acceleration():
    """Set up GPU acceleration for training."""
    print("=== GPU/TPU ACCELERATION SETUP ===")
    
    # Check for TPU
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('üöÄ Running on TPU:', tpu.master())
        tf.config.experimental_connect_to_cluster(tpu)
        tf.tpu.experimental.initialize_tpu_system(tpu)
        tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)
        print(f'TPU devices: {tpu_strategy.num_replicas_in_sync}')
        return 'tpu', tpu_strategy
    except:
        print('‚ùå TPU not available')
    
    # Check for GPU
    if torch.cuda.is_available():
        print(f'üöÄ GPU available: {torch.cuda.get_device_name(0)}')
        print(f'GPU count: {torch.cuda.device_count()}')
        return 'gpu', torch.cuda.device_count()
    
    # Check TensorFlow GPU
    if tf.config.list_physical_devices('GPU'):
        gpus = tf.config.list_physical_devices('GPU')
        print(f'üöÄ TensorFlow GPU devices: {len(gpus)}')
        return 'gpu', len(gpus)
    
    print('‚ö†Ô∏è  No GPU/TPU available, using CPU')
    return 'cpu', 1

# Initialize acceleration
device_type, device_count = setup_gpu_acceleration()
print(f"\nüéØ Using: {device_type.upper()} with {device_count} device(s)")

# =============================================================================
# CELL 4: Load CSV Data
# =============================================================================

print("üìä Loading processed CSV data...")

# Load the processed CSV file
df = pd.read_csv('/kaggle/input/flight-delay-data/flights_processed.csv')

print(f"‚úÖ Data loaded successfully!")
print(f"üìà Original data shape: {df.shape}")
print(f"üìã Columns: {list(df.columns)}")

# Display basic info
print(f"\nüìä Dataset Info:")
print(f"  Total samples: {len(df):,}")
print(f"  Features: {df.shape[1]}")
print(f"  Missing values: {df.isnull().sum().sum()}")

# Show target distribution
print(f"\nüéØ Target Distribution (is_delayed_15min):")
print(f"  Delayed (1): {df['is_delayed_15min'].sum():,} ({df['is_delayed_15min'].mean():.1%})")
print(f"  On-time (0): {(1-df['is_delayed_15min']).sum():,} ({(1-df['is_delayed_15min']).mean():.1%})")

# =============================================================================
# CELL 5: Feature Engineering and Data Splitting
# =============================================================================

print("\nüîß Preparing features for machine learning...")

# Define target variable
target = 'is_delayed_15min'

# Remove target columns and other non-feature columns
exclude_cols = ['ARR_DELAY', 'is_delayed_any', 'is_delayed_30min', 'is_delayed_15min', 'FL_DATE']
feature_cols = [col for col in df.columns if col not in exclude_cols]

print(f"üìã Using {len(feature_cols)} features for training")
print(f"üéØ Target variable: {target}")

# Prepare features and target
X = df[feature_cols]
y = df[target]

# Identify categorical and numeric features
categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()
numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()

print(f"\nüìä Feature types:")
print(f"  Numeric features: {len(numeric_features)}")
print(f"  Categorical features: {len(categorical_features)}")

# Handle categorical features with label encoding
X_encoded = X.copy()
label_encoders = {}

for col in categorical_features:
    le = LabelEncoder()
    X_encoded[col] = le.fit_transform(X_encoded[col].astype(str))
    label_encoders[col] = le
    print(f"  Encoded {col}: {X_encoded[col].nunique()} unique values")

# Split data into train and test sets using sklearn
X_train, X_test, y_train, y_test = train_test_split(
    X_encoded, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nüìà Data split using sklearn train_test_split:")
print(f"  Training set: {X_train.shape[0]:,} samples")
print(f"  Test set: {X_test.shape[0]:,} samples")
print(f"  Train positive rate: {y_train.mean():.3f}")
print(f"  Test positive rate: {y_test.mean():.3f}")

# =============================================================================
# CELL 6: Train Decision Tree with Hyperparameter Tuning
# =============================================================================

print("\nüå≥ TRAINING DECISION TREE WITH GPU ACCELERATION")

# Determine optimal n_jobs based on device type
if device_type == 'tpu':
    n_jobs = device_count * 8
elif device_type == 'gpu':
    n_jobs = device_count * 4
else:
    n_jobs = -1

print(f"‚ö° Using {n_jobs} parallel jobs for grid search...")

# Define parameter grid
param_grid = {
    'max_depth': [10, 15, 20],
    'min_samples_split': [50, 100, 200],
    'min_samples_leaf': [25, 50, 100],
    'max_features': ['sqrt', 'log2']
}

# Create base model
dt_base = DecisionTreeClassifier(
    random_state=42,
    class_weight='balanced'
)

# Grid search with cross-validation
print("üîç Performing grid search...")
grid_search = GridSearchCV(
    dt_base, 
    param_grid, 
    cv=3, 
    scoring='f1', 
    n_jobs=n_jobs, 
    verbose=1
)

grid_search.fit(X_train, y_train)

print(f"\nüéØ Best parameters: {grid_search.best_params_}")
print(f"üèÜ Best CV score: {grid_search.best_score_:.4f}")

# Get best model and make predictions
best_dt_model = grid_search.best_estimator_
dt_pred = best_dt_model.predict(X_test)
dt_proba = best_dt_model.predict_proba(X_test)[:, 1]

# Calculate metrics
dt_accuracy = accuracy_score(y_test, dt_pred)
dt_precision = precision_score(y_test, dt_pred)
dt_recall = recall_score(y_test, dt_pred)
dt_f1 = f1_score(y_test, dt_pred)
dt_auc = roc_auc_score(y_test, dt_proba)

print(f"\nüìä Decision Tree Results:")
print(f"  Accuracy:  {dt_accuracy:.4f}")
print(f"  Precision: {dt_precision:.4f}")
print(f"  Recall:    {dt_recall:.4f}")
print(f"  F1-Score:  {dt_f1:.4f}")
print(f"  AUC-ROC:   {dt_auc:.4f}")

# =============================================================================
# CELL 7: Train Random Forest
# =============================================================================

print("\nüå≤ TRAINING RANDOM FOREST WITH GPU ACCELERATION")

rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=15,
    min_samples_split=50,
    min_samples_leaf=25,
    class_weight='balanced',
    random_state=42,
    n_jobs=n_jobs
)

print("üèÉ Training Random Forest...")
rf_model.fit(X_train, y_train)

# Make predictions
rf_pred = rf_model.predict(X_test)
rf_proba = rf_model.predict_proba(X_test)[:, 1]

# Calculate metrics
rf_accuracy = accuracy_score(y_test, rf_pred)
rf_precision = precision_score(y_test, rf_pred)
rf_recall = recall_score(y_test, rf_pred)
rf_f1 = f1_score(y_test, rf_pred)
rf_auc = roc_auc_score(y_test, rf_proba)

print(f"\nüìä Random Forest Results:")
print(f"  Accuracy:  {rf_accuracy:.4f}")
print(f"  Precision: {rf_precision:.4f}")
print(f"  Recall:    {rf_recall:.4f}")
print(f"  F1-Score:  {rf_f1:.4f}")
print(f"  AUC-ROC:   {rf_auc:.4f}")

# =============================================================================
# CELL 8: Train Gradient Boosting
# =============================================================================

print("\nüöÄ TRAINING GRADIENT BOOSTING")

gb_model = GradientBoostingClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    random_state=42
)

print("üèÉ Training Gradient Boosting...")
gb_model.fit(X_train, y_train)

# Make predictions
gb_pred = gb_model.predict(X_test)
gb_proba = gb_model.predict_proba(X_test)[:, 1]

# Calculate metrics
gb_accuracy = accuracy_score(y_test, gb_pred)
gb_precision = precision_score(y_test, gb_pred)
gb_recall = recall_score(y_test, gb_pred)
gb_f1 = f1_score(y_test, gb_pred)
gb_auc = roc_auc_score(y_test, gb_proba)

print(f"\nüìä Gradient Boosting Results:")
print(f"  Accuracy:  {gb_accuracy:.4f}")
print(f"  Precision: {gb_precision:.4f}")
print(f"  Recall:    {gb_recall:.4f}")
print(f"  F1-Score:  {gb_f1:.4f}")
print(f"  AUC-ROC:   {gb_auc:.4f}")

# =============================================================================
# CELL 9: Model Performance Comparison
# =============================================================================

print("\nüìä MODEL PERFORMANCE COMPARISON")

# Create comparison dataframe
results_df = pd.DataFrame({
    'Model': ['Decision Tree', 'Random Forest', 'Gradient Boosting'],
    'Accuracy': [dt_accuracy, rf_accuracy, gb_accuracy],
    'Precision': [dt_precision, rf_precision, gb_precision],
    'Recall': [dt_recall, rf_recall, gb_recall],
    'F1-Score': [dt_f1, rf_f1, gb_f1],
    'AUC-ROC': [dt_auc, rf_auc, gb_auc]
})

print("\nüèÜ Final Results Summary:")
print(results_df.round(4))

# Find best model for each metric
print("\nü•á Best Model by Metric:")
for metric in ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']:
    best_idx = results_df[metric].idxmax()
    best_model = results_df.loc[best_idx, 'Model']
    best_score = results_df.loc[best_idx, metric]
    print(f"  {metric}: {best_model} ({best_score:.4f})")

# =============================================================================
# CELL 10: Visualizations
# =============================================================================

print("\nüìà Creating Performance Visualizations...")

# Model comparison bar chart
fig, axes = plt.subplots(2, 3, figsize=(18, 12))
axes = axes.flatten()

metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']
colors = ['skyblue', 'lightgreen', 'lightcoral']

for i, metric in enumerate(metrics):
    ax = axes[i]
    bars = ax.bar(results_df['Model'], results_df[metric], color=colors)
    ax.set_title(f'{metric} Comparison', fontsize=14, fontweight='bold')
    ax.set_ylabel(metric)
    ax.set_ylim(0, 1)
    
    # Add value labels on bars
    for bar, value in zip(bars, results_df[metric]):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{value:.3f}', ha='center', va='bottom', fontweight='bold')

# Overall performance status
axes[5].text(0.5, 0.5, f'GPU Accelerated\nTraining Complete!\n\nDevice: {device_type.upper()}', 
             ha='center', va='center', fontsize=16, fontweight='bold',
             transform=axes[5].transAxes)
axes[5].set_title('Training Status', fontsize=14, fontweight='bold')
axes[5].axis('off')

plt.suptitle('Flight Delay Prediction - Model Performance Comparison (GPU Accelerated)', 
             fontsize=16, fontweight='bold')
plt.tight_layout()
plt.show()

# =============================================================================
# CELL 11: ROC Curves and Feature Importance
# =============================================================================

# ROC Curves Comparison
plt.figure(figsize=(10, 8))

models_data = [
    ('Decision Tree', dt_proba, dt_auc),
    ('Random Forest', rf_proba, rf_auc),
    ('Gradient Boosting', gb_proba, gb_auc)
]

for model_name, proba, auc in models_data:
    fpr, tpr, _ = roc_curve(y_test, proba)
    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.3f})', linewidth=2)

plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier', alpha=0.5)
plt.xlabel('False Positive Rate', fontsize=12)
plt.ylabel('True Positive Rate', fontsize=12)
plt.title('ROC Curves Comparison - Flight Delay Prediction', fontsize=14, fontweight='bold')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# Feature Importance (using Random Forest)
print("\nüîç TOP 15 MOST IMPORTANT FEATURES:")
importances = rf_model.feature_importances_
feature_importance_df = pd.DataFrame({
    'feature': X_train.columns,
    'importance': importances
}).sort_values('importance', ascending=False)

print(feature_importance_df.head(15))

# Plot feature importance
plt.figure(figsize=(12, 8))
top_features = feature_importance_df.head(20)
sns.barplot(data=top_features, x='importance', y='feature')
plt.title('Top 20 Feature Importances - Random Forest', fontsize=14, fontweight='bold')
plt.xlabel('Importance')
plt.tight_layout()
plt.show()

# =============================================================================
# CELL 12: Final Summary
# =============================================================================

print("\n" + "="*60)
print("üéâ FLIGHT DELAY PREDICTION - TRAINING COMPLETE!")
print("="*60)

print(f"\nüöÄ Device Used: {device_type.upper()} with {device_count} device(s)")
print(f"üìä Dataset: {len(df):,} total samples")
print(f"üéØ Target: 15+ minute delays ({df[target].mean():.1%} positive class)")
print(f"üìà Features: {X_train.shape[1]} (after encoding)")

print(f"\nüèÜ BEST MODEL PERFORMANCE:")
best_model_row = results_df.loc[results_df['F1-Score'].idxmax()]
for metric in ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']:
    print(f"  {metric}: {best_model_row[metric]:.4f}")

print(f"\n‚úÖ All models trained successfully with GPU acceleration!")
print(f"üìà Complete analysis with visualizations finished.")

# =============================================================================
# END OF FINAL NOTEBOOK
# =============================================================================
